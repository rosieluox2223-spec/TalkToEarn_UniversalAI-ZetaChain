# app.py - åŸºäºAILibrariesçš„å¤šç”¨æˆ·AIçŸ¥è¯†åº“åˆ†äº«å¹³å°
import os
import json
import numpy as np
from dotenv import load_dotenv
import sqlite3

# åŠ è½½.envæ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
load_dotenv()
from flask import Flask, request, jsonify, Response, render_template, session, redirect, url_for
from flask_socketio import SocketIO, emit
import chardet
import time
from langchain_core.documents import Document
import uuid
from werkzeug.utils import secure_filename
import math
import hashlib
from datetime import datetime

# ==================== å¯¼å…¥å¿…è¦çš„åº“ ====================
from langchain_text_splitters import RecursiveCharacterTextSplitter, TokenTextSplitter
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_community.document_loaders import PyPDFLoader, TextLoader
from langchain_chroma import Chroma
from langchain_community.embeddings import DashScopeEmbeddings
from langchain_community.chat_models import ChatTongyi

from flask_cors import CORS

# ipfsåŠŸèƒ½è°ƒç”¨
from upload_ipfs import upload_text_and_get_preview_url


app = Flask(__name__)
app.secret_key = 'your-secret-key-here'

# åˆå§‹åŒ–SocketIOï¼Œå¯ç”¨CORSæ”¯æŒ
socketio = SocketIO(app, cors_allowed_origins="*")

CORS(
    app,
    resources={r"/connect_wallet": {"origins": "*"}},
)

# ==================== æ–‡ä»¶è·¯å¾„é…ç½® ====================
UPLOAD_FOLDER = 'USER_DATA'
SHARED_FOLDER = 'SHARED_CONTENT'
USER_DB_FILE = 'users.json'
FILES_DB_FILE = 'files.json'
TRANSACTIONS_DB_FILE = 'transactions.json'
SQLITE_DB_FILE = 'talktoearn.db'

os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(SHARED_FOLDER, exist_ok=True)

# ==================== é˜¿é‡ŒQwen API é…ç½® ====================
# ä»ç¯å¢ƒå˜é‡è·å–APIå¯†é’¥ï¼Œæ”¯æŒQWEN_API_KEYå’ŒDASHSCOPE_API_KEY
API_KEY = os.getenv('QWEN_API_KEY', os.getenv('DASHSCOPE_API_KEY', 'your-api-key'))

# æ·»åŠ è°ƒè¯•ä¿¡æ¯
print(f"ğŸš¨ API_KEYåŠ è½½ç»“æœ: {API_KEY[:8]}...{API_KEY[-4:]}" if len(API_KEY) > 12 else f"ğŸš¨ API_KEYæ— æ•ˆ: {API_KEY}")
print(f"ğŸš¨ ç¯å¢ƒå˜é‡QWEN_API_KEYæ˜¯å¦å­˜åœ¨: {'æ˜¯' if os.getenv('QWEN_API_KEY') else 'å¦'}")
print(f"ğŸš¨ ç¯å¢ƒå˜é‡DASHSCOPE_API_KEYæ˜¯å¦å­˜åœ¨: {'æ˜¯' if os.getenv('DASHSCOPE_API_KEY') else 'å¦'}")

# åˆå§‹åŒ–QwenåµŒå…¥æ¨¡å‹
embeddings = DashScopeEmbeddings(
    model="text-embedding-v2",
    dashscope_api_key=API_KEY
)

# åˆå§‹åŒ–QwenèŠå¤©æ¨¡å‹
llm = ChatTongyi(
    model="qwen-turbo",
    temperature=0.3,
    dashscope_api_key=API_KEY
)

# æµ‹è¯•APIè¿æ¥
print("ğŸ” æ­£åœ¨æµ‹è¯•Qwen APIè¿æ¥...")
try:
    test_response = llm.invoke("æµ‹è¯•è¿æ¥")
    print("âœ… APIè¿æ¥æµ‹è¯•æˆåŠŸ!")
except Exception as e:
    print(f"âŒ APIè¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}")
    import traceback
    traceback.print_exc()

vector_store = None

# ==================== æ•°æ®åº“åˆå§‹åŒ– ====================

def init_db():
    """åˆå§‹åŒ–SQLiteæ•°æ®åº“å¹¶åˆ›å»ºè¡¨"""
    conn = sqlite3.connect(SQLITE_DB_FILE)
    cursor = conn.cursor()
    
    # åˆ›å»ºç”¨æˆ·è¡¨
    cursor.execute('''
    CREATE TABLE IF NOT EXISTS users (
        user_id TEXT PRIMARY KEY,
        password_hash TEXT NOT NULL,
        coin_balance REAL DEFAULT 1.0,
        total_earned REAL DEFAULT 0.0,
        total_spent REAL DEFAULT 0.0,
        registration_time TEXT NOT NULL,
        wallet_account TEXT UNIQUE
    )
    ''')
    
    # åˆ›å»ºç”¨æˆ·ä¸Šä¼ æ–‡ä»¶è¡¨
    cursor.execute('''
    CREATE TABLE IF NOT EXISTS uploaded_files (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        user_id TEXT NOT NULL,
        file_id TEXT NOT NULL,
        upload_time TEXT DEFAULT CURRENT_TIMESTAMP,
        FOREIGN KEY (user_id) REFERENCES users (user_id) ON DELETE CASCADE
    )
    ''')
    
    # åˆ›å»ºç”¨æˆ·å¼•ç”¨æ–‡ä»¶è¡¨
    cursor.execute('''
    CREATE TABLE IF NOT EXISTS referenced_files (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        user_id TEXT NOT NULL,
        file_id TEXT NOT NULL,
        question TEXT NOT NULL,
        reward REAL NOT NULL,
        timestamp TEXT NOT NULL,
        similarity REAL NOT NULL,
        weight REAL NOT NULL,
        FOREIGN KEY (user_id) REFERENCES users (user_id) ON DELETE CASCADE
    )
    ''')

 # åˆ›å»ºæ–‡ç« è¡¨
    cursor.execute('''
    CREATE TABLE IF NOT EXISTS files (
        id TEXT PRIMARY KEY,
        filename TEXT NOT NULL,
        user_id TEXT NOT NULL,
        content TEXT,
        content_preview TEXT,
        upload_time TEXT,
        authorize_rag INTEGER,
        reference_count INTEGER,
        total_reward REAL,
        file_path TEXT,
        ipfs_url TEXT, 
        total_staked REAL DEFAULT 0.0)
    ''')
    
    # åˆ›å»ºè´¨æŠ¼è®°å½•è¡¨
    cursor.execute('''
    CREATE TABLE IF NOT EXISTS stakes (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        file_id TEXT NOT NULL,
        wallet_address TEXT NOT NULL,
        amount REAL NOT NULL,
        content_id TEXT NOT NULL,
        stake_time TEXT DEFAULT CURRENT_TIMESTAMP
    )
    ''')
    
    conn.commit()
    conn.close()

def migrate_from_json_to_db():
    """ä»JSONæ–‡ä»¶è¿ç§»æ•°æ®åˆ°SQLiteæ•°æ®åº“"""
    conn = sqlite3.connect(SQLITE_DB_FILE)
    cursor = conn.cursor()
    
    # æ£€æŸ¥ç”¨æˆ·è¡¨æ˜¯å¦ä¸ºç©º
    cursor.execute('SELECT COUNT(*) FROM users')
    if cursor.fetchone()[0] == 0:
        # ä»JSONæ–‡ä»¶åŠ è½½ç”¨æˆ·æ•°æ®
        if os.path.exists(USER_DB_FILE):
            with open(USER_DB_FILE, 'r', encoding='utf-8') as f:
                users = json.load(f)
            
            # è¿ç§»ç”¨æˆ·æ•°æ®
            for user_id, user_data in users.items():
                # æ’å…¥ç”¨æˆ·åŸºæœ¬ä¿¡æ¯
                cursor.execute('''
                INSERT INTO users (user_id, password_hash, coin_balance, total_earned, total_spent, registration_time, wallet_account)
                VALUES (?, ?, ?, ?, ?, ?, ?)
                ''', (
                    user_id,
                    user_data['password_hash'],
                    user_data['coin_balance'],
                    user_data['total_earned'],
                    user_data['total_spent'],
                    user_data['registration_time'],
                    user_data.get('wallet_account')  # å¤„ç† JSON ä¸­å¯èƒ½ä¸å­˜åœ¨çš„å­—æ®µ
                ))
                
                # è¿ç§»ä¸Šä¼ æ–‡ä»¶æ•°æ®
                for file_id in user_data['uploaded_files']:
                    cursor.execute('''
                    INSERT INTO uploaded_files (user_id, file_id)
                    VALUES (?, ?)
                    ''', (user_id, file_id))
                
                # è¿ç§»å¼•ç”¨æ–‡ä»¶æ•°æ®
                for ref_file in user_data['referenced_files']:
                    cursor.execute('''
                    INSERT INTO referenced_files (user_id, file_id, question, reward, timestamp, similarity, weight)
                    VALUES (?, ?, ?, ?, ?, ?, ?)
                    ''', (
                        user_id,
                        ref_file['file_id'],
                        ref_file['question'],
                        ref_file['reward'],
                        ref_file['timestamp'],
                        ref_file['similarity'],
                        ref_file['weight']
                    ))
    
    # æ£€æŸ¥filesè¡¨æ˜¯å¦ä¸ºç©ºï¼Œè¿ç§»æ–‡ä»¶æ•°æ®
    cursor.execute('SELECT COUNT(*) FROM files')
    if cursor.fetchone()[0] == 0:
        # ä»JSONæ–‡ä»¶åŠ è½½æ–‡ä»¶æ•°æ®
        if os.path.exists(FILES_DB_FILE):
            with open(FILES_DB_FILE, 'r', encoding='utf-8') as f:
                files_data = json.load(f)
            
            # è¿ç§»æ–‡ä»¶æ•°æ®
            for file_id, file_info in files_data.items():
                cursor.execute('''
                INSERT INTO files (id, filename, user_id, content, content_preview, upload_time, 
                                  authorize_rag, reference_count, total_reward, file_path, ipfs_url, total_staked)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    file_id,
                    file_info['filename'],
                    file_info['user_id'],
                    file_info['content'],
                    file_info['content_preview'],
                    file_info['upload_time'],
                    file_info.get('authorize_rag', 1),
                    file_info.get('reference_count', 0),
                    file_info.get('total_reward', 0.0),
                    file_info.get('file_path', ''),
                    file_info.get('ipfs_url', ''),
                    file_info.get('total_staked', 0.0)
                ))
                print(f"âœ… å·²è¿ç§»æ–‡ä»¶: {file_id} - {file_info['filename']}")
    
    conn.commit()
    conn.close()

# åˆå§‹åŒ–æ•°æ®åº“
init_db()
# ä»JSONè¿ç§»æ•°æ®åˆ°æ•°æ®åº“
migrate_from_json_to_db()

# ==================== ç”¨æˆ·ç®¡ç†ç³»ç»Ÿ ====================

# æ•°æ®åº“è¿æ¥è¾…åŠ©å‡½æ•°
def get_db_connection():
    conn = sqlite3.connect(SQLITE_DB_FILE)
    conn.row_factory = sqlite3.Row  # è¿”å›å­—å…¸å½¢å¼çš„è¡Œ
    return conn

# æ›¿ä»£åŸæ¥çš„load_userså‡½æ•°
def get_user(user_id):
    conn = get_db_connection()
    user = conn.execute('SELECT * FROM users WHERE user_id = ?', (user_id,)).fetchone()
    conn.close()
    return user

def load_users():
    if os.path.exists(USER_DB_FILE):
        with open(USER_DB_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}

# æ›¿ä»£åŸæ¥çš„save_userså‡½æ•°
def update_user(user_id, **kwargs):
    conn = get_db_connection()
    cursor = conn.cursor()
    
    # æ„å»ºæ›´æ–°è¯­å¥
    columns = ', '.join([f"{col} = ?" for col in kwargs.keys()])
    values = list(kwargs.values()) + [user_id]
    
    cursor.execute(f"UPDATE users SET {columns} WHERE user_id = ?", values)
    conn.commit()
    conn.close()

def save_users(users):
    with open(USER_DB_FILE, 'w', encoding='utf-8') as f:
        json.dump(users, f, ensure_ascii=False, indent=2)
    # print("save_user")

def add_user(user_id, password_hash, coin_balance=1.0, total_earned=0.0, total_spent=0.0, registration_time=None, wallet_account=None):
    # print("add_add_user")
    conn = get_db_connection()
    cursor = conn.cursor()
    
    if registration_time is None:
        registration_time = datetime.now().isoformat()
    
    cursor.execute('''
    INSERT INTO users (user_id, password_hash, coin_balance, total_earned, total_spent, registration_time, wallet_account)
    VALUES (?, ?, ?, ?, ?, ?, ?)
    ''', (user_id, password_hash, coin_balance, total_earned, total_spent, registration_time, wallet_account))
    
    conn.commit()
    conn.close()

def add_user_list(user_id):
    # print("add_user")
    users = load_users()
    users[user_id] = {
        'password_hash': hash_password(123456),
        'coin_balance': 1.0,
        'total_earned': 0.0,  # ğŸ¯ ç¡®ä¿åˆå§‹åŒ–ä¸º0
        'total_spent': 0.0,   # ğŸ¯ ç¡®ä¿åˆå§‹åŒ–ä¸º0
        'registration_time': datetime.now().isoformat(),
        'uploaded_files': [],
        'referenced_files': []  # ğŸ¯ ç¡®ä¿è¿™ä¸ªå­—æ®µå­˜åœ¨
    }
    # print("load_user ")
    save_users(users)
    

# ä¸Šä¼ æ–‡ä»¶ç›¸å…³å‡½æ•°
def add_uploaded_file(user_id, file_id):
    conn = get_db_connection()
    cursor = conn.cursor()
    
    cursor.execute('''
    INSERT INTO uploaded_files (user_id, file_id)
    VALUES (?, ?)
    ''', (user_id, file_id))
    
    conn.commit()
    conn.close()

def get_uploaded_files(user_id):
    conn = get_db_connection()
    cursor = conn.cursor()
    
    cursor.execute('SELECT file_id FROM uploaded_files WHERE user_id = ?', (user_id,))
    files = [row[0] for row in cursor.fetchall()]
    
    conn.close()
    return files

# å¼•ç”¨æ–‡ä»¶ç›¸å…³å‡½æ•°
def add_referenced_file(user_id, file_id, question, reward, timestamp, similarity, weight):
    conn = get_db_connection()
    cursor = conn.cursor()
    
    cursor.execute('''
    INSERT INTO referenced_files (user_id, file_id, question, reward, timestamp, similarity, weight)
    VALUES (?, ?, ?, ?, ?, ?, ?)
    ''', (user_id, file_id, question, reward, timestamp, similarity, weight))
    
    conn.commit()
    conn.close()

def get_referenced_files(user_id):
    conn = get_db_connection()
    cursor = conn.cursor()
    
    cursor.execute('SELECT * FROM referenced_files WHERE user_id = ?', (user_id,))
    refs = [dict(row) for row in cursor.fetchall()]
    
    conn.close()
    return refs

def load_files():
    if os.path.exists(FILES_DB_FILE):
        with open(FILES_DB_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}

def save_files(files):
    with open(FILES_DB_FILE, 'w', encoding='utf-8') as f:
        json.dump(files, f, ensure_ascii=False, indent=2)

def load_transactions():
    if os.path.exists(TRANSACTIONS_DB_FILE):
        with open(TRANSACTIONS_DB_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return []

def save_transactions(transactions):
    with open(TRANSACTIONS_DB_FILE, 'w', encoding='utf-8') as f:
        json.dump(transactions, f, ensure_ascii=False, indent=2)

def hash_password(password):
    return hashlib.sha256(password.encode()).hexdigest()

# def register_user(user_id, password):
#     conn = get_db_connection()
    
#     # æ£€æŸ¥ç”¨æˆ·IDæ˜¯å¦å·²å­˜åœ¨
#     existing_user = conn.execute('SELECT * FROM users WHERE user_id = ?', (user_id,)).fetchone()
#     if existing_user:
#         conn.close()
#         return False, "ç”¨æˆ·IDå·²å­˜åœ¨"
    
#     # åˆ›å»ºæ–°ç”¨æˆ·
#     add_user(user_id, hash_password(password))
#     conn.close()
#     return True, "æ³¨å†ŒæˆåŠŸ"

def authenticate_user(user_id, password):
    conn = get_db_connection()
    user = conn.execute('SELECT * FROM users WHERE user_id = ?', (user_id,)).fetchone()
    conn.close()
    
    if not user:
        return False, "ç”¨æˆ·ä¸å­˜åœ¨"
    
    if user['password_hash'] != hash_password(password):
        return False, "å¯†ç é”™è¯¯"
    
    return True, "ç™»å½•æˆåŠŸ"

def get_user_stats(user_id):
    conn = get_db_connection()
    user = conn.execute('SELECT * FROM users WHERE user_id = ?', (user_id,)).fetchone()
    
    if not user:
        conn.close()
        return None
    
    # è·å–ä¸Šä¼ æ–‡ä»¶æ•°é‡
    uploaded_files_count = conn.execute('SELECT COUNT(*) FROM uploaded_files WHERE user_id = ?', (user_id,)).fetchone()[0]
    conn.close()
    
    # è·å–äº¤æ˜“æ•°æ®
    transactions = load_transactions()
    today = datetime.now().date()
    
    today_earned = 0.0
    today_references = 0
    
    for tx in transactions:
        tx_time = datetime.fromisoformat(tx['timestamp']).date()
        if tx_time == today:
            if tx['type'] == 'reward' and tx['to_user'] == user_id:
                today_earned += tx['amount']
            elif tx['type'] == 'reference' and tx['file_owner'] == user_id:
                today_references += 1
    
    return {
        'coin_balance': user['coin_balance'],
        'total_earned': user['total_earned'],
        'total_spent': user['total_spent'],
        'today_earned': today_earned,
        'today_references': today_references,
        'uploaded_files_count': uploaded_files_count
    }

def get_user_status(user_id):
    users = load_users()
    if user_id not in users:
        return None
    
    user = users[user_id]
    transactions = load_transactions()
    today = datetime.now().date()
    
    today_earned = 0.0
    today_references = 0
    
    for tx in transactions:
        tx_time = datetime.fromisoformat(tx['timestamp']).date()
        if tx_time == today:
            if tx['type'] == 'reward' and tx['to_user'] == user_id:
                today_earned += tx['amount']
            elif tx['type'] == 'reference' and tx['file_owner'] == user_id:
                today_references += 1
    
    return {
        'coin_balance': user['coin_balance'],
        'total_earned': user['total_earned'],
        'total_spent': user['total_spent'],
        'today_earned': today_earned,
        'today_references': today_references,
        'uploaded_files_count': len(user['uploaded_files'])
    }


@app.route('/connect_wallet', methods=['POST','OPTIONS'])
def connect_wallet():
    """å¤„ç†é’±åŒ…è¿æ¥è¯·æ±‚"""
    print("å¼€å§‹è¿æ¥é’±åŒ…")
    if request.method == 'OPTIONS':
        return jsonify({'success': True}), 200
    # data = request.get_json()
    data = request.get_json(silent=True) or {}
    wallet_address = data.get('wallet_address')
    print(wallet_address)
    if not wallet_address:
        return jsonify({'success': False, 'message': 'é’±åŒ…åœ°å€ä¸èƒ½ä¸ºç©º'})
    

    #æ£€æŸ¥ç”¨æˆ·æ˜¯å¦åœ¨åˆ—è¡¨
    users = load_users()
    user_id = wallet_address
    password = '123456'
    
    if user_id in users:
        print("é’±åŒ…ç”¨æˆ·å·²åœ¨åˆ—è¡¨")
    else:
        print("æ–°ç”¨æˆ·åˆ›å»º")
        users[user_id] = {
        'password_hash': hash_password(password),
        'coin_balance': 1.0,
        'total_earned': 0.0,  #åˆå§‹åŒ–ä¸º0
        'total_spent': 0.0,   # åˆå§‹åŒ–ä¸º0
        'registration_time': datetime.now().isoformat(),
        'uploaded_files': [],
        'referenced_files': []  #è¿™ä¸ªå­—æ®µå­˜åœ¨
        } 
        save_users(users)

    # æ£€æŸ¥é’±åŒ…åœ°å€æ˜¯å¦å·²å­˜åœ¨
    conn = get_db_connection()
    existing_user = conn.execute('SELECT * FROM users WHERE wallet_account = ?', (wallet_address,)).fetchone()
    
    if existing_user:
        # é’±åŒ…åœ°å€å·²å­˜åœ¨ï¼Œè¿”å›ç”¨æˆ·ä¿¡æ¯
        conn.close()
        return jsonify({
            'success': True,
            'message': 'é’±åŒ…å·²è¿æ¥',
            'user_id': existing_user['user_id'],
            'wallet_account': existing_user['wallet_account']
        })

    # é’±åŒ…åœ°å€ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°ç”¨æˆ·
    try:
        print("è¿æ¥ç”¨æˆ·åˆ—è¡¨")
        # ä½¿ç”¨é’±åŒ…åœ°å€ä½œä¸º user_idï¼Œé»˜è®¤å¯†ç  123456
        user_id = wallet_address
        password = '123456'
        
        # æ£€æŸ¥ user_id æ˜¯å¦å·²å­˜åœ¨
        user_exists = conn.execute('SELECT * FROM users WHERE user_id = ?', (user_id,)).fetchone()
        if user_exists:
            conn.close()
            return jsonify({'success': False, 'message': 'ç”¨æˆ·IDå·²å­˜åœ¨'})
        
        # åˆ›å»ºæ–°ç”¨æˆ·
        add_user(user_id, hash_password(password))
        
        # æ›´æ–°é’±åŒ…åœ°å€
        update_user(user_id, wallet_account=wallet_address)
        
        conn.close()
        
        return jsonify({
            'success': True,
            'message': 'é’±åŒ…å·²è¿æ¥å¹¶åˆ›å»ºæ–°ç”¨æˆ·',
            'user_id': user_id,
            'wallet_account': wallet_address,
            'default_password': password  # æç¤ºç”¨æˆ·ä½¿ç”¨é»˜è®¤å¯†ç ç™»å½•
        })
    except Exception as e:
        conn.close()
        return jsonify({'success': False, 'message': f'è¿æ¥é’±åŒ…å¤±è´¥: {str(e)}'})


def calculate_user_earnings(user_id):
    """é‡æ–°è®¡ç®—ç”¨æˆ·çš„æ€»æ”¶ç›Š - ä¿®å¤ç»Ÿè®¡é—®é¢˜"""
    conn = get_db_connection()
    user = conn.execute('SELECT * FROM users WHERE user_id = ?', (user_id,)).fetchone()
    
    if not user:
        conn.close()
        return 0.0, 0.0, 0
    
    transactions = load_transactions()
    
    total_earned = 0.0
    total_spent = 0.0
    reference_count = 0
    
    # é‡æ–°è®¡ç®—æ‰€æœ‰äº¤æ˜“
    for tx in transactions:
        # è®¡ç®—æ”¶ç›Šï¼ˆå¥–åŠ±å’Œå¼•ç”¨ï¼‰
        if tx['to_user'] == user_id and tx['type'] in ['reward', 'reference']:
            total_earned += tx['amount']
            if tx['type'] == 'reference':
                reference_count += 1
        # è®¡ç®—æ”¯å‡º
        elif tx['from_user'] == user_id and tx['type'] == 'spend':
            total_spent += tx['amount']
    
    # ç¡®ä¿ä½™é¢æ­£ç¡®
    initial_balance = 1.0  # æ³¨å†Œæ—¶èµ é€çš„1coin
    calculated_balance = initial_balance + total_earned - total_spent
    calculated_balance = max(0, calculated_balance)  # ä½™é¢ä¸èƒ½ä¸ºè´Ÿ
    
    # æ›´æ–°ç”¨æˆ·æ•°æ®
    update_user(user_id, total_earned=total_earned, total_spent=total_spent, coin_balance=calculated_balance)
    conn.close()



    
    print(f"ğŸ’° ç”¨æˆ· {user_id} æ”¶ç›Šç»Ÿè®¡: æ€»æ”¶ç›Š={total_earned:.6f}, æ€»æ”¯å‡º={total_spent:.6f}, å¼•ç”¨æ¬¡æ•°={reference_count}")
    
    return total_earned, total_spent, reference_count


def record_transaction(tx_type, from_user, to_user, amount, file_owner=None, file_id=None, question=None):
    """ä¿®å¤äº¤æ˜“è®°å½•å‡½æ•° - ç¡®ä¿ä½™é¢æ­£ç¡®æ›´æ–°"""
    transactions = load_transactions()
    
    transaction = {
        'id': str(uuid.uuid4()),
        'type': tx_type,
        'from_user': from_user,
        'to_user': to_user,
        'amount': amount,
        'file_owner': file_owner,
        'file_id': file_id,
        'question': question,
        'timestamp': datetime.now().isoformat()
    }
    
    transactions.append(transaction)
    save_transactions(transactions)
    
    print(f"ğŸ’¾ è®°å½•äº¤æ˜“: {tx_type}, ä» {from_user} åˆ° {to_user}, é‡‘é¢ {amount:.8f}")
    
    conn = get_db_connection()
    
    if tx_type == 'spend' and from_user:
        # ç¡®ä¿ä½™é¢ä¸ä¼šå˜æˆè´Ÿæ•°
        conn.execute('''
        UPDATE users SET 
            coin_balance = MAX(0, coin_balance - ?),
            total_spent = total_spent + ?
        WHERE user_id = ?
        ''', (amount, amount, from_user))
        print(f"ğŸ’¸ ç”¨æˆ· {from_user} æ”¯å‡º {amount:.8f}")
    
    if tx_type == 'reward' and to_user:
        conn.execute('''
        UPDATE users SET 
            coin_balance = coin_balance + ?,
            total_earned = total_earned + ?
        WHERE user_id = ?
        ''', (amount, amount, to_user))
        print(f"ğŸ ç”¨æˆ· {to_user} è·å¾—å¥–åŠ± {amount:.8f}")
    
    conn.commit()
    conn.close()
    
    # å†æ¬¡éªŒè¯æ•°æ®æ˜¯å¦ä¿å­˜æˆåŠŸ
    if to_user and tx_type == 'reward':
        user = get_user(to_user)
        print(f"âœ… æœ€ç»ˆéªŒè¯: ç”¨æˆ· {to_user} ä½™é¢å·²æ›´æ–°ä¸º {user['coin_balance']:.6f}")
    if from_user and tx_type == 'spend':
        user = get_user(from_user)
        print(f"âœ… æœ€ç»ˆéªŒè¯: ç”¨æˆ· {from_user} ä½™é¢å·²æ›´æ–°ä¸º {user['coin_balance']:.6f}")

@app.route('/profile')
def user_profile():
    users = load_users()
    wallet_address = request.args.get('wallet_address', '').strip()
    print("wallet_address:", wallet_address)

    print("wallet_address:", wallet_address)

    if wallet_address not in users:
        return jsonify({'success': False, 'message': 'é’±åŒ…æœªæ³¨å†Œï¼Œè¯·å…ˆè¿æ¥é’±åŒ…'})
    
    user_id = wallet_address

    
    # ğŸ¯ é‡æ–°è®¡ç®—ç”¨æˆ·æ”¶ç›Šç¡®ä¿æ•°æ®å‡†ç¡®
    total_earned, total_spent, _ = calculate_user_earnings(user_id)
    
    # é‡æ–°åŠ è½½æœ€æ–°æ•°æ®
    user = get_user(user_id)
    
    if not user:
        return redirect('/logout')
    
    # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ä»¥ä¾¿æ¨¡æ¿ä½¿ç”¨
    user_dict = dict(user)
    
    # è·å–ä¸Šä¼ æ–‡ä»¶å’Œå¼•ç”¨æ–‡ä»¶
    user_dict['uploaded_files'] = get_uploaded_files(user_id)
    user_dict['referenced_files'] = get_referenced_files(user_id)
    
    transactions = load_transactions()
    
    # è·å–ç”¨æˆ·çš„äº¤æ˜“è®°å½•
    user_transactions = []
    for tx in transactions:
        if tx['from_user'] == user_id or tx['to_user'] == user_id:
            user_transactions.append(tx)
    
    # æŒ‰æ—¶é—´å€’åºæ’åˆ—ï¼Œå–æœ€è¿‘20æ¡
    user_transactions.sort(key=lambda x: x['timestamp'], reverse=True)
    recent_transactions = user_transactions[:20]
    
    # è·å–ç”¨æˆ·æ–‡ä»¶å¼•ç”¨ç»Ÿè®¡
    user_files = search_files(user_id=user_id)
    reference_stats = []
    
    for file_info in user_files:
        file_references = [tx for tx in transactions 
                          if tx.get('file_id') == file_info['file_id'] and tx['type'] == 'reference']
        reference_stats.append({
            'file_id': file_info['file_id'],
            'filename': file_info['filename'],
            'reference_count': len(file_references),
            'total_reward': file_info.get('total_reward', 0)
        })
    
    # è®¡ç®—ä»Šæ—¥æ”¶ç›Š
    today = datetime.now().date()
    today_earned = 0.0
    today_references = 0
    
    for tx in transactions:
        if tx['to_user'] == user_id and tx['type'] == 'reward':
            tx_time = datetime.fromisoformat(tx['timestamp']).date()
            if tx_time == today:
                today_earned += tx['amount']
        elif tx.get('file_owner') == user_id and tx['type'] == 'reference':
            tx_time = datetime.fromisoformat(tx['timestamp']).date()
            if tx_time == today:
                today_references += 1
    
    # è°ƒè¯•ä¿¡æ¯
    print(f"ğŸ“Š Profileé¡µé¢ - ç”¨æˆ·: {user_id}")
    print(f"ğŸ’° ä½™é¢: {user['coin_balance']:.6f}")
    print(f"ğŸ“ˆ æ€»æ”¶ç›Š: {user['total_earned']:.6f}")
    print(f"ğŸ“‰ æ€»æ”¯å‡º: {user['total_spent']:.6f}")
    print(f"ğŸ“ æ–‡ä»¶æ•°: {len(user_files)}")
    print(f"ğŸ“‹ äº¤æ˜“è®°å½•æ•°: {len(recent_transactions)}")
    print(f"ğŸ¯ ä»Šæ—¥æ”¶ç›Š: {today_earned:.6f}, ä»Šæ—¥å¼•ç”¨: {today_references}")
    
    return render_template('profile.html',
                         user_id=user_id,
                         user=user_dict,
                         transactions=recent_transactions,
                         reference_stats=reference_stats,
                         today_earned=today_earned,
                         today_references=today_references)


# ==================== æ–‡ä»¶ç®¡ç†ç³»ç»Ÿ ====================
#å¢è®¾ipfsä¸Šä¼ åŠŸèƒ½
def save_shared_file(user_id, filename, content, authorize_rag=True):
    files = load_files()
    
    # ç”Ÿæˆæ–‡ä»¶ID - ç¡®ä¿æ ¼å¼æ­£ç¡®
    file_id = f"{datetime.now().strftime('%Y%m%d%H%M%S')}_{user_id}"
    
    # åˆ›å»ºæ–‡ä»¶è·¯å¾„ - ä½¿ç”¨æ–‡ä»¶IDä½œä¸ºæ–‡ä»¶å
    filepath = os.path.join(SHARED_FOLDER, f"{file_id}.txt")
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(content)
    
    try:
        preview_url = upload_text_and_get_preview_url(
        text_content=content,
        name=filename,
        description=file_id,
        file_name=filename
    )
        print("æµè§ˆipfs-url:", preview_url)

    except Exception as e:
        print("ä¸Šä¼ å¤±è´¥:", e)

    ipfs_url=str(preview_url)
    files[file_id] = {
        'filename': filename,
        'user_id': user_id,
        'content': content,
        'content_preview': content[:200] + "..." if len(content) > 200 else content,
        'upload_time': datetime.now().isoformat(),
        'authorize_rag': authorize_rag,
        'reference_count': 0,
        'total_reward': 0.0,
        'file_path': filepath,
        'ipfs_url': ipfs_url
    }
    
    save_files(files)

    users = load_users()
    if user_id in users:
        users[user_id]['uploaded_files'].append(file_id)
        save_users(users)
    
    # ä½¿ç”¨æ•°æ®åº“æ·»åŠ ä¸Šä¼ æ–‡ä»¶è®°å½•
    add_uploaded_file(user_id, file_id)
    
    if authorize_rag:
        try:
            print(f"å¼€å§‹å°†æ–‡ä»¶æ·»åŠ åˆ°çŸ¥è¯†åº“: {file_id}, æ–‡ä»¶å: {filename}")
            add_file_to_vector_store(filepath, file_id, user_id, filename,ipfs_url)
            print(f"æˆåŠŸå°†æ–‡ä»¶æ·»åŠ åˆ°çŸ¥è¯†åº“: {file_id}")
        except Exception as e:
            print(f"æ·»åŠ åˆ°çŸ¥è¯†åº“å¤±è´¥: {e}")
    
    return file_id

def add_file_to_vector_store(filepath, file_id, user_id, filename,ipfs_url):
    global vector_store

    try:
        init_vector_store(filepath,None,None,None,ipfs_url)
        print(f"æˆåŠŸæ·»åŠ æ–‡ä»¶åˆ°çŸ¥è¯†åº“: {filename}")
    except Exception as e:
        print(f"æ·»åŠ æ–‡ä»¶åˆ°å‘é‡åº“å¤±è´¥: {e}")
        raise

# # åœ¨ app.py ä¸­æ‰¾åˆ° search_files å‡½æ•°ï¼Œå¹¶è¿›è¡Œç±»ä¼¼å¦‚ä¸‹ä¿®æ”¹
# def search_files(file_id=None, user_id=None, keyword=None):
#     files = load_files()
#     results = []
    
#     for fid, file_info in files.items():
#         match = True
        
#         if file_id and fid != file_id:
#             match = False
#         if user_id and file_info['user_id'] != user_id:
#             match = False
#         if keyword:
#             # æ‰©å±•æœç´¢èŒƒå›´ï¼šåŒæ—¶åŒ¹é…æ–‡ä»¶IDã€æ–‡ä»¶åå’Œæ–‡ä»¶å†…å®¹
#             keyword_lower = keyword.lower()
#             file_id_match = (fid.lower().find(keyword_lower) != -1)
#             filename_match = (file_info['filename'].lower().find(keyword_lower) != -1)
#             content_match = (file_info['content'].lower().find(keyword_lower) != -1)
            
#             if not (file_id_match or filename_match or content_match):
#                 match = False
                
#         if match:
#             results.append({
#                 'file_id': fid,
#                 **file_info
#             })
    
#     return sorted(results, key=lambda x: x['upload_time'], reverse=True)

def search_files_in_content(files, keyword):
    """åœ¨æ–‡ä»¶å†…å®¹ä¸­æœç´¢å…³é”®è¯"""
    keyword_lower = keyword.lower()
    results = []
    
    for file_id, file_data in files.items():
        # æœç´¢æ–‡ä»¶å
        if keyword_lower in file_data.get('filename', '').lower():
            results.append(file_id)
            continue
            
        # æœç´¢æ–‡ä»¶å†…å®¹
        if keyword_lower in file_data.get('content', '').lower():
            results.append(file_id)
            continue
            
        # æœç´¢æ–‡ä»¶ID
        if keyword_lower in file_id.lower():
            results.append(file_id)
            continue
            
        # æœç´¢ç”¨æˆ·ID
        if keyword_lower in file_data.get('user_id', '').lower():
            results.append(file_id)
    
    return results


# ==================== æ™ºèƒ½å¥–åŠ±åˆ†é…ç³»ç»Ÿ ====================

def calculate_reward_distribution(relevant_docs, total_cost):
    """ä¿®å¤å¥–åŠ±è®¡ç®—å‡½æ•°"""
    if not relevant_docs:
        print("âš ï¸ æ²¡æœ‰ç›¸å…³æ–‡æ¡£ï¼Œæ— æ³•åˆ†é…å¥–åŠ±")
        return {}
    
    similarities = []
    file_similarities = {}
    
    print(f"ğŸ“Š å¼€å§‹è®¡ç®—å¥–åŠ±åˆ†å¸ƒ: æ€»æˆæœ¬ {total_cost:.6f}, æ–‡æ¡£æ•° {len(relevant_docs)}")
    
    for doc in relevant_docs:
        file_id = doc.metadata.get('file_id')
        similarity = doc.metadata.get('semantic_similarity', 0.3)
        
        print(f"ğŸ“„ æ–‡æ¡£ {file_id}: ç›¸ä¼¼åº¦ {similarity:.3f}")
        
        if file_id:
            if file_id not in file_similarities:
                file_similarities[file_id] = []
            file_similarities[file_id].append(similarity)
            similarities.append(similarity)
    
    if not similarities:
        print("âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„ç›¸ä¼¼åº¦æ•°æ®")
        return {}
    
    # è®¡ç®—æ¯ä¸ªæ–‡ä»¶çš„å¹³å‡ç›¸ä¼¼åº¦
    file_avg_similarities = {}
    for file_id, sim_list in file_similarities.items():
        file_avg_similarities[file_id] = sum(sim_list) / len(sim_list)
        print(f"ğŸ“ˆ æ–‡ä»¶ {file_id}: å¹³å‡ç›¸ä¼¼åº¦ {file_avg_similarities[file_id]:.3f}")
        send_system_message('info', f"æ–‡ä»¶ {file_id}: å¹³å‡ç›¸ä¼¼åº¦ {file_avg_similarities[file_id]:.3f}")
    
    total_similarity = sum(file_avg_similarities.values())
    print(f"ğŸ“Š æ€»ç›¸ä¼¼åº¦: {total_similarity:.3f}")
    send_system_message('info', f"æ€»ç›¸ä¼¼åº¦: {total_similarity:.3f}")
    
    if total_similarity == 0:
        print("âš ï¸ æ€»ç›¸ä¼¼åº¦ä¸º0ï¼Œæ— æ³•åˆ†é…å¥–åŠ±")
        return {}
    
    reward_distribution = {}
    for file_id, avg_similarity in file_avg_similarities.items():
        weight = avg_similarity / total_similarity
        reward = weight * total_cost
        
        print(f"ğŸ’° æ–‡ä»¶ {file_id}: æƒé‡ {weight:.3f}, å¥–åŠ± {reward:.8f} coin")
        send_system_message('info', f"æ–‡ä»¶ {file_id}: æƒé‡ {weight:.3f}, å¥–åŠ± {reward:.8f} coin")
        
        reward_distribution[file_id] = {
            'reward': reward,
            'weight': weight,
            'similarity': avg_similarity
        }
    
    total_distributed = sum(info['reward'] for info in reward_distribution.values())
    print(f"ğŸ¯ æ€»åˆ†é…é‡‘é¢: {total_distributed:.8f} coin")
    send_system_message('info', f"æ€»åˆ†é…é‡‘é¢: {total_distributed:.8f} coin")
    
    return reward_distribution

def distribute_rewards(user_id, question, relevant_docs, total_cost):
    """ä¿®å¤å¥–åŠ±åˆ†é…å‡½æ•° - ç¡®ä¿å¥–åŠ±æ­£ç¡®åˆ†é…å’Œè®°å½•"""
    reward_distribution = calculate_reward_distribution(relevant_docs, total_cost)
    
    files = load_files()
    transactions = load_transactions()
    
    distribution_info = {}
    total_distributed = 0.0
    
    print(f"ğŸ” å¼€å§‹å¥–åŠ±åˆ†é…: æ€»æˆæœ¬ {total_cost:.6f}, ç›¸å…³æ–‡æ¡£ {len(relevant_docs)} ä¸ª")
    send_system_message('info', f"å¼€å§‹å¥–åŠ±åˆ†é…: æ€»æˆæœ¬ {total_cost:.6f}, ç›¸å…³æ–‡æ¡£ {len(relevant_docs)} ä¸ª")
    
    conn = get_db_connection()
    
    for file_id, reward_info in reward_distribution.items():
        try:
            # å°è¯•æ‰¾åˆ°åŒ¹é…çš„æ–‡ä»¶
            file_info = None
            if file_id and file_id in files:

                print('---------',file_id)

                file_info = files[file_id]
            else:
                # å¦‚æœfile_idä¸åŒ¹é…ï¼Œå°è¯•é€šè¿‡æ–‡ä»¶åæˆ–å†…å®¹åŒ¹é…
                print(f"âš ï¸ æ–‡ä»¶ID {file_id} ä¸åœ¨files.jsonä¸­ï¼Œå°è¯•å…¶ä»–åŒ¹é…æ–¹å¼")
                
                # å°è¯•é€šè¿‡æ–‡ä»¶ååŒ¹é…ï¼ˆå»æ‰_teståç¼€ï¼‰
                base_file_id = file_id.replace('_test', '') if file_id else ''
                print(f"ğŸ” å°è¯•åŸºç¡€æ–‡ä»¶ååŒ¹é…: {base_file_id}")
                
                for actual_file_id, actual_file_info in files.items():
                    # æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦åŒ…å«åŸºç¡€file_idæˆ–å†…å®¹æ˜¯å¦åŒ¹é…
                    if base_file_id and (
                        base_file_id in actual_file_id or 
                        base_file_id in actual_file_info.get('filename', '') or
                        ('ç¼–ç¨‹è¯­è¨€' in actual_file_info.get('content', '') and file_id == 'code_test')
                    ):
                        print(f"âœ… æ‰¾åˆ°åŒ¹é…æ–‡ä»¶: {actual_file_id} (åŸfile_id: {file_id})")
                        file_info = actual_file_info
                        file_id = actual_file_id  # æ›´æ–°file_idä¸ºå®é™…çš„file_id
                        break
                
                if not file_info:
                    print(f"âŒ æ— æ³•æ‰¾åˆ°ä¸ {file_id} åŒ¹é…çš„æ–‡ä»¶")
                
            if file_info:
                file_owner = file_info['user_id']
                reward_amount = reward_info['reward']
                
                # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å­˜åœ¨
                cursor = conn.cursor()
                cursor.execute('SELECT * FROM users WHERE user_id = ?', (file_owner,))
                user = cursor.fetchone()
                if user and reward_amount > 0:
                    try:
                        # æ›´æ–°ç”¨æˆ·ä½™é¢å’Œæ€»æ”¶ç›Š
                        cursor.execute('''
                        UPDATE users SET 
                            coin_balance = coin_balance + ?,
                            total_earned = total_earned + ?
                        WHERE user_id = ?
                        ''', (reward_amount, reward_amount, file_owner))
                        
                        # è®°å½•å¥–åŠ±äº¤æ˜“
                        reward_tx = {
                            'id': str(uuid.uuid4()),
                            'type': 'reward',
                            'from_user': None,  # ç³»ç»Ÿå‘æ”¾
                            'to_user': file_owner,
                            'amount': reward_amount,
                            'file_owner': file_owner,
                            'file_id': file_id,
                            'question': question,
                            'timestamp': datetime.now().isoformat()
                        }
                        transactions.append(reward_tx)
                        
                        # è®°å½•å¼•ç”¨äº¤æ˜“
                        reference_tx = {
                            'id': str(uuid.uuid4()),
                            'type': 'reference',
                            'from_user': user_id,
                            'to_user': file_owner,
                            'amount': 0.0,  # å¼•ç”¨è®°å½•ï¼Œé‡‘é¢ä¸º0
                            'file_owner': file_owner,
                            'file_id': file_id,
                            'question': question,
                            'timestamp': datetime.now().isoformat()
                        }
                        transactions.append(reference_tx)
                        
                        # æ›´æ–°æ–‡ä»¶ç»Ÿè®¡
                        files[file_id]['reference_count'] += 1
                        files[file_id]['total_reward'] += reward_amount

                        users=load_users()
                        if 'referenced_files' not in users[file_owner]:
                            users[file_owner]['referenced_files'] = []
                    
                        reference_record = {
                                'file_id': file_id,
                                'question': question,
                                'reward': reward_amount,
                                'timestamp': datetime.now().isoformat(),
                                'similarity': reward_info.get('similarity', 0),
                                'weight': reward_info.get('weight', 0)
                                }           
                        users[file_owner]['referenced_files'].append(reference_record)
                        save_users(users)
                        
                        total_distributed += reward_amount
                        
                        # è·å–file_ownerçš„é’±åŒ…åœ°å€
                        wallet_account = user['wallet_account'] if user['wallet_account'] else 'æœªç»‘å®šé’±åŒ…'
                        
                        print(f"âœ… æˆåŠŸåˆ†é…å¥–åŠ±: {file_owner} (é’±åŒ…: {wallet_account}) è·å¾— {reward_amount:.8f} coin")
                        print(f"ğŸ” é’±åŒ…åœ°å€ç±»å‹: {type(wallet_account)}, å€¼: {wallet_account}")
                        print(f"ğŸ” é’±åŒ…åœ°å€æ¯”è¾ƒ: wallet_account != 'æœªç»‘å®šé’±åŒ…' -> {wallet_account != 'æœªç»‘å®šé’±åŒ…'}")
                        
                        send_system_message('success', f"æˆåŠŸåˆ†é…å¥–åŠ±: {file_owner} (é’±åŒ…: {wallet_account}) è·å¾— {reward_amount:.8f} coin")
                        
                        # å‘é€è½¬è´¦æ„å›¾åˆ°å‰ç«¯
                        if wallet_account and wallet_account != 'æœªç»‘å®šé’±åŒ…' and wallet_account != '':
                            print(f"ğŸš€ å‘é€è½¬è´¦æ„å›¾åˆ°å‰ç«¯ï¼Œé’±åŒ…åœ°å€: {wallet_account}")
                            transfer_intent = {
                                "action": "transfer",
                                "fromChain": "zetachain",
                                "toChain": "zetachain",
                                "fromToken": "ZETA",
                                "toToken": "ZETA",
                                "amount": "0.01",
                                "recipient": wallet_account
                            }
                            socketio.emit('system_message', {'type': 'intent', 'data': transfer_intent}, namespace='/ws')
                            print(f"âœ… è½¬è´¦æ„å›¾å‘é€æˆåŠŸ")
                        else:
                            print(f"âŒ ä¸å‘é€è½¬è´¦æ„å›¾: é’±åŒ…åœ°å€æ— æ•ˆ -> {wallet_account}")
                    except Exception as e:
                        print(f"âŒ å¥–åŠ±åˆ†é…å¤±è´¥ {file_id}: {e}")
            else:
                print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶ {file_id} çš„åŒ¹é…ä¿¡æ¯")
        except Exception as e:
            print(f"âŒ å¤„ç†æ–‡ä»¶ {file_id} æ—¶å‡ºé”™: {e}")
    
    # ç¡®ä¿æ•°æ®ä¿å­˜
    save_files(files)
    save_transactions(transactions)
    conn.commit()
    conn.close()
    
    print(f"ğŸ¯ å¥–åŠ±åˆ†é…å®Œæˆ: æ€»åˆ†é…é‡‘é¢ {total_distributed:.8f} coin")
    send_system_message('success', f"å¥–åŠ±åˆ†é…å®Œæˆ: æ€»åˆ†é…é‡‘é¢ {total_distributed:.8f} coin")
    return distribution_info

def extract_file_id_from_source(source):
    """ä»æ–‡ä»¶è·¯å¾„ä¸­æå–file_id"""
    if not source:
        return None
    
    # ä»æ–‡ä»¶è·¯å¾„ä¸­æå–æ–‡ä»¶åï¼ˆä¸å¸¦æ‰©å±•åï¼‰
    filename = os.path.basename(source)
    if '.' in filename:
        file_id = filename.split('.')[0]  # å»æ‰æ‰©å±•å
    else:
        file_id = filename
    
    print(f"ğŸ” ä»sourceæå–file_id: {source} -> {file_id}")
    return file_id

def calculate_reward_distribution(relevant_docs, total_cost):
    """ä¿®å¤å¥–åŠ±è®¡ç®—å‡½æ•° - å¤„ç†file_idä¸ºNoneçš„æƒ…å†µ"""
    if not relevant_docs:
        print("âš ï¸ æ²¡æœ‰ç›¸å…³æ–‡æ¡£ï¼Œæ— æ³•åˆ†é…å¥–åŠ±")
        send_system_message('warning', "æ²¡æœ‰ç›¸å…³æ–‡æ¡£ï¼Œæ— æ³•åˆ†é…å¥–åŠ±")
        return {}
    
    similarities = []
    file_similarities = {}
    
    print(f"ğŸ“Š å¼€å§‹è®¡ç®—å¥–åŠ±åˆ†å¸ƒ: æ€»æˆæœ¬ {total_cost:.6f}, æ–‡æ¡£æ•° {len(relevant_docs)}")
    send_system_message('info', f"å¼€å§‹è®¡ç®—å¥–åŠ±åˆ†å¸ƒ: æ€»æˆæœ¬ {total_cost:.6f}, æ–‡æ¡£æ•° {len(relevant_docs)}")
    
    for doc in relevant_docs:
        file_id = doc.metadata.get('file_id')
        similarity = doc.metadata.get('semantic_similarity', 0.3)
        
        # å¦‚æœfile_idä¸ºNoneï¼Œå°è¯•ä»sourceä¸­æå–
        if file_id is None:
            source = doc.metadata.get('source', '')
            file_id = extract_file_id_from_source(source)
            print(f"ğŸ”„ è®¡ç®—å¥–åŠ±æ—¶æå–file_id: {source} -> {file_id}")
        
        print(f"ğŸ“„ æ–‡æ¡£ {file_id}: ç›¸ä¼¼åº¦ {similarity:.3f}")
        send_system_message('info', f"æ–‡æ¡£ {file_id}: ç›¸ä¼¼åº¦ {similarity:.3f}")
        
        if file_id:
            if file_id not in file_similarities:
                file_similarities[file_id] = []
            file_similarities[file_id].append(similarity)
            similarities.append(similarity)
    
    if not similarities:
        print("âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„ç›¸ä¼¼åº¦æ•°æ®")
        return {}
    
    # è®¡ç®—æ¯ä¸ªæ–‡ä»¶çš„å¹³å‡ç›¸ä¼¼åº¦
    file_avg_similarities = {}
    for file_id, sim_list in file_similarities.items():
        file_avg_similarities[file_id] = sum(sim_list) / len(sim_list)
        print(f"ğŸ“ˆ æ–‡ä»¶ {file_id}: å¹³å‡ç›¸ä¼¼åº¦ {file_avg_similarities[file_id]:.3f}")
    
    total_similarity = sum(file_avg_similarities.values())
    print(f"ğŸ“Š æ€»ç›¸ä¼¼åº¦: {total_similarity:.3f}")
    
    if total_similarity == 0:
        print("âš ï¸ æ€»ç›¸ä¼¼åº¦ä¸º0ï¼Œæ— æ³•åˆ†é…å¥–åŠ±")
        return {}
    
    reward_distribution = {}
    for file_id, avg_similarity in file_avg_similarities.items():
        weight = avg_similarity / total_similarity
        reward = weight * total_cost
        
        print(f"ğŸ’° æ–‡ä»¶ {file_id}: æƒé‡ {weight:.3f}, å¥–åŠ± {reward:.8f} coin")
        
        reward_distribution[file_id] = {
            'reward': reward,
            'weight': weight,
            'similarity': avg_similarity
        }
    
    total_distributed = sum(info['reward'] for info in reward_distribution.values())
    print(f"ğŸ¯ æ€»åˆ†é…é‡‘é¢: {total_distributed:.8f} coin")
    
    return reward_distribution



# ==================== ä»AILibrarieså¤åˆ¶çš„æ ¸å¿ƒAIåŠŸèƒ½ ====================

def enhanced_cosine_similarity(vec1, vec2):
    vec1 = np.array(vec1).flatten()
    vec2 = np.array(vec2).flatten()
    
    if np.all(vec1 == 0) or np.all(vec2 == 0):
        return 0.0
    
    dot_product = np.dot(vec1, vec2)
    norm_vec1 = np.linalg.norm(vec1)
    norm_vec2 = np.linalg.norm(vec2)
    
    if norm_vec1 == 0 or norm_vec2 == 0:
        return 0.0
    
    similarity = dot_product / (norm_vec1 * norm_vec2)
    similarity = max(-1.0, min(1.0, similarity))
    
    return float(similarity)

def llm_based_relevance_check(question, document_content, llm_model):
    try:
        truncated_content = document_content[:800] + "..." if len(document_content) > 800 else document_content
        
        prompt = f"""è¯·ä¸¥æ ¼åˆ¤æ–­ä»¥ä¸‹æ–‡æ¡£å†…å®¹æ˜¯å¦ä¸ç”¨æˆ·é—®é¢˜ç›¸å…³ã€‚è¯·åªå›ç­”"ç›¸å…³"æˆ–"ä¸ç›¸å…³"ï¼Œä¸è¦è§£é‡Šã€‚

ç”¨æˆ·é—®é¢˜ï¼š{question}

æ–‡æ¡£å†…å®¹ï¼š{truncated_content}

è¯·åˆ¤æ–­æ–‡æ¡£å†…å®¹æ˜¯å¦ä¸ç”¨æˆ·é—®é¢˜ç›¸å…³ï¼Œåªå›ç­”"ç›¸å…³"æˆ–"ä¸ç›¸å…³"ï¼š"""
        
        response = llm_model.invoke(prompt)
        response_text = response.content.strip().lower()
        print(f"LLMç›¸å…³æ€§åˆ¤æ–­ç»“æœ: '{response_text}'")
        
        return "ç›¸å…³" in response_text and "ä¸ç›¸å…³" not in response_text
        
    except Exception as e:
        print(f"LLMç›¸å…³æ€§åˆ¤æ–­é”™è¯¯: {e}")
        return False

def hybrid_relevance_check(question, doc, embeddings_model, llm_model):
    semantic_similarity = calculate_semantic_similarity(question, doc.page_content, embeddings_model)
    
    # æ£€æµ‹æ˜¯å¦æ˜¯æ¦‚å¿µæ€§é—®é¢˜
    is_conceptual_question = any(keyword in question for keyword in 
                                ["ä»€ä¹ˆæ˜¯", "ä»€ä¹ˆå«", "å®šä¹‰", "æ¦‚å¿µ", "å«ä¹‰", "è§£é‡Š", "ä¸ºä»€ä¹ˆ"])
    
    if semantic_similarity > 0.7:
        return True, semantic_similarity
    elif semantic_similarity > 0.3 or (is_conceptual_question and semantic_similarity > 0.2):
        # å¯¹äºæ¦‚å¿µæ€§é—®é¢˜ï¼Œé™ä½é˜ˆå€¼åˆ°0.2ï¼Œç»™äºˆLLMåˆ¤æ–­çš„æœºä¼š
        is_llm_relevant = llm_based_relevance_check(question, doc.page_content, llm_model)
        return is_llm_relevant, semantic_similarity
    else:
        return False, semantic_similarity

def calculate_jaccard_similarity(text1, text2):
    words1 = set(text1.lower().split())
    words2 = set(text2.lower().split())
    
    if not words1 and not words2:
        return 0.0
    
    intersection = len(words1.intersection(words2))
    union = len(words1.union(words2))
    
    return intersection / union if union > 0 else 0.0

def calculate_semantic_similarity(question, document_content, embeddings_model):
    try:
        question_embedding = embeddings_model.embed_query(question)
        doc_embedding = embeddings_model.embed_query(document_content)
        
        base_similarity = enhanced_cosine_similarity(question_embedding, doc_embedding)
        
        is_conceptual_question = any(keyword in question for keyword in 
                                    ["ä»€ä¹ˆæ˜¯", "ä»€ä¹ˆå«", "å®šä¹‰", "æ¦‚å¿µ", "å«ä¹‰", "è§£é‡Š"])
        
        doc_length = len(document_content.split())
        if is_conceptual_question:
            length_factor = min(1.0, doc_length / 25)
        else:
            length_factor = min(1.0, doc_length / 40)
        
        jaccard_similarity = calculate_jaccard_similarity(question, document_content)
        
        concept_keywords = {
            "çˆ±": ["çˆ±", "çˆ±æƒ…", "çˆ±å¿ƒ", "å…³çˆ±", "çƒ­çˆ±", "æƒ…æ„Ÿ", "æ„Ÿæƒ…", "å…³ç³»", "äº²å¯†", "å®šä¹‰", "æ¦‚å¿µ"],
            "ä»€ä¹ˆæ˜¯": ["å®šä¹‰", "æ¦‚å¿µ", "å«ä¹‰", "è§£é‡Š", "æ˜¯ä»€ä¹ˆ", "ä»€ä¹ˆå«", "æ„å‘³ç€", "æŒ‡çš„æ˜¯"],
            "ç¼–ç¨‹è¯­è¨€": ["ç¼–ç¨‹", "è¯­è¨€", "ç¼–ç¨‹è¯­è¨€", "ä»£ç ", "ç¨‹åº", "è®¡ç®—æœº", "è¯­æ³•", "è¯­ä¹‰", "åŠŸèƒ½"]
        }
        
        keyword_boost = 0.0
        for concept, keywords in concept_keywords.items():
            if concept in question:
                keyword_matches = sum(1 for keyword in keywords if keyword in document_content)
                if keyword_matches > 0:
                    if is_conceptual_question:
                        keyword_boost = min(0.25, keyword_matches * 0.08)
                    else:
                        keyword_boost = min(0.15, keyword_matches * 0.05)
                    print(f"å…³é”®è¯åŒ¹é…å¢å¼º: åŒ¹é…åˆ° {keyword_matches} ä¸ªç›¸å…³å…³é”®è¯ï¼Œæå‡ {keyword_boost:.3f}")
                    break
        
        question_len = len(question)
        doc_len = len(document_content)
        if question_len > 0 and doc_len > 0:
            length_similarity = 1 - abs(question_len - doc_len) / (question_len + doc_len)
        else:
            length_similarity = 0
        
        if is_conceptual_question:
            semantic_similarity = (
                0.75 * base_similarity +
                0.05 * jaccard_similarity +
                0.1 * length_factor +
                0.1 * length_similarity +
                keyword_boost
            )
            semantic_similarity = 1 / (1 + math.exp(-6 * (semantic_similarity - 0.4)))
        else:
            semantic_similarity = (
                0.8 * base_similarity +
                0.05 * jaccard_similarity +
                0.1 * length_factor +
                0.05 * length_similarity +
                keyword_boost
            )
            semantic_similarity = 1 / (1 + math.exp(-10 * (semantic_similarity - 0.55)))
        
        print(f"ç›¸ä¼¼åº¦åˆ†è§£ - è¯­ä¹‰:{base_similarity:.3f}, Jaccard:{jaccard_similarity:.3f}, é•¿åº¦å› å­:{length_factor:.3f}, å…³é”®è¯å¢å¼º:{keyword_boost:.3f}, ç»¼åˆ:{semantic_similarity:.3f}")
        
        return semantic_similarity
        
    except Exception as e:
        print(f"è¯­ä¹‰ç›¸ä¼¼åº¦è®¡ç®—é”™è¯¯: {e}")
        return 0.4

def adaptive_filter_relevant_docs(question, docs, embeddings_model, llm_model):
    relevant_docs = []
    
    print(f"å¼€å§‹è‡ªé€‚åº”è¿‡æ»¤ {len(docs)} ä¸ªæ–‡æ¡£")
    
    is_conceptual_question = any(keyword in question for keyword in 
                                ["ä»€ä¹ˆæ˜¯", "ä»€ä¹ˆå«", "å®šä¹‰", "æ¦‚å¿µ", "å«ä¹‰", "è§£é‡Š", "ä¸ºä»€ä¹ˆ"])
    
    if is_conceptual_question:
        print("æ£€æµ‹åˆ°æ¦‚å¿µæ€§é—®é¢˜ï¼Œé‡‡ç”¨LLMä¸»å¯¼çš„è¿‡æ»¤ç­–ç•¥")
    
    for i, doc in enumerate(docs):
        try:
            is_relevant, similarity = hybrid_relevance_check(question, doc, embeddings_model, llm_model)
            
            doc_preview = doc.page_content[:50] + "..." if len(doc.page_content) > 50 else doc.page_content
            print(f"æ–‡æ¡£ {i+1} æ··åˆç›¸ä¼¼åº¦: {similarity:.3f}, ç›¸å…³: {is_relevant} - å†…å®¹: {doc_preview}")
            
            if is_relevant:
                doc.metadata['semantic_similarity'] = float(similarity)
                relevant_docs.append((similarity, doc))
                
        except Exception as e:
            print(f"æ–‡æ¡£ {i+1} ç›¸å…³æ€§åˆ¤æ–­é”™è¯¯: {e}")
            doc.metadata['semantic_similarity'] = 0.4
            relevant_docs.append((0.4, doc))
    
    if not relevant_docs:
        return []
    
    relevant_docs.sort(key=lambda x: x[0], reverse=True)
    
    llm_relevant_docs = [doc for similarity, doc in relevant_docs]
    
    if is_conceptual_question:
        max_docs = min(6, len(llm_relevant_docs))
        filtered_docs = llm_relevant_docs[:max_docs]
        print(f"æ¦‚å¿µæ€§é—®é¢˜ - ä¿ç•™æ‰€æœ‰LLMåˆ¤æ–­ç›¸å…³çš„æ–‡æ¡£: {len(filtered_docs)} ä¸ª")
    else:
        similarities = [similarity for similarity, doc in relevant_docs]
        if len(similarities) > 0:
            avg_similarity = sum(similarities) / len(similarities)
            dynamic_threshold = max(0.40, avg_similarity + 0.2 * math.sqrt(sum((x - avg_similarity) ** 2 for x in similarities) / len(similarities)))
            filtered_docs = [doc for similarity, doc in relevant_docs if similarity >= dynamic_threshold]
            filtered_docs = filtered_docs[:4]
            print(f"æ™®é€šé—®é¢˜ - åŠ¨æ€é˜ˆå€¼: {dynamic_threshold:.3f}, ä¿ç•™: {len(filtered_docs)} ä¸ªæ–‡æ¡£")
        else:
            filtered_docs = llm_relevant_docs[:3]
    
    print(f"è¿‡æ»¤åä¿ç•™ {len(filtered_docs)} ä¸ªç›¸å…³æ–‡æ¡£")
    return filtered_docs

def intelligent_rag_decision(question, relevant_docs):
    if not relevant_docs:
        return False, "æ²¡æœ‰ç›¸å…³æ–‡æ¡£", 0.0
    
    similarities = [doc.metadata.get('semantic_similarity', 0) for doc in relevant_docs]
    max_similarity = max(similarities) if similarities else 0
    avg_similarity = sum(similarities) / len(similarities) if similarities else 0
    
    print(f"RAGå†³ç­– - æœ€é«˜ç›¸ä¼¼åº¦: {max_similarity:.3f}, å¹³å‡ç›¸ä¼¼åº¦: {avg_similarity:.3f}")
    
    is_conceptual_question = any(keyword in question for keyword in 
                                ["ä»€ä¹ˆæ˜¯", "ä»€ä¹ˆå«", "å®šä¹‰", "æ¦‚å¿µ", "å«ä¹‰", "è§£é‡Š", "ä¸ºä»€ä¹ˆ"])
    
    if is_conceptual_question:
        if len(relevant_docs) == 0:
            return False, "æ²¡æœ‰ç›¸å…³æ–‡æ¡£", 0.0
        else:
            doc_count_factor = min(1.0, len(relevant_docs) / 3.0)
            similarity_factor = min(1.0, max_similarity / 0.7)
            
            confidence = 0.5 + 0.3 * doc_count_factor + 0.2 * similarity_factor
            confidence = min(0.9, confidence)
            
            return True, f"æ‰¾åˆ° {len(relevant_docs)} ä¸ªç›¸å…³æ–‡æ¡£ (æœ€é«˜ç›¸ä¼¼åº¦:{max_similarity:.3f})", confidence
    else:
        if max_similarity < 0.45:
            return False, f"æœ€é«˜ç›¸ä¼¼åº¦ {max_similarity:.3f} è¿‡ä½", max_similarity
        elif avg_similarity < 0.40:
            return False, f"å¹³å‡ç›¸ä¼¼åº¦ {avg_similarity:.3f} è¿‡ä½", max_similarity
        else:
            confidence = min(1.0, (max_similarity - 0.5) * 2.0)
            return True, f"æ–‡æ¡£ç›¸å…³æ€§è¶³å¤Ÿ (æœ€é«˜:{max_similarity:.3f}, å¹³å‡:{avg_similarity:.3f})", confidence

def hybrid_answering_strategy(question, relevant_docs, confidence):
    is_conceptual_question = any(keyword in question for keyword in 
                                ["ä»€ä¹ˆæ˜¯", "ä»€ä¹ˆå«", "å®šä¹‰", "æ¦‚å¿µ", "å«ä¹‰", "è§£é‡Š", "ä¸ºä»€ä¹ˆ"])
    
    # å°†æ–‡æ¡£å†…å®¹è¿æ¥æˆå­—ç¬¦ä¸²ï¼Œé¿å…åœ¨f-stringä¸­ç›´æ¥ä½¿ç”¨å¯èƒ½åŒ…å«åæ–œæ çš„å†…å®¹
    docs_content = "\n\n".join([doc.page_content for doc in relevant_docs])
    
    if confidence > 0.7:
        strategy = "high_confidence_rag"
        prompt = """è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ä¿¡æ¯å›ç­”é—®é¢˜ï¼š

ç›¸å…³ä¸Šä¸‹æ–‡ï¼š
{}

é—®é¢˜ï¼š{}

è¯·åŸºäºä¸Šè¿°ä¸Šä¸‹æ–‡æä¾›å‡†ç¡®å›ç­”ï¼š"""
        prompt = prompt.format(docs_content, question)
        
    elif confidence > 0.4:
        strategy = "balanced_hybrid" 
        prompt = """è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ä¿¡æ¯å›ç­”é—®é¢˜ï¼ŒåŒæ—¶å¯ä»¥é€‚å½“ç»“åˆä½ çš„çŸ¥è¯†è¿›è¡Œè¡¥å……ï¼š

ç›¸å…³ä¸Šä¸‹æ–‡ï¼š
{}

é—®é¢˜ï¼š{}

è¯·ä¼˜å…ˆä½¿ç”¨ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¦‚æœä¸Šä¸‹æ–‡ä¿¡æ¯ä¸è¶³å¯ä»¥ç»“åˆä½ çš„çŸ¥è¯†è¿›è¡Œè¡¥å……ï¼š"""
        prompt = prompt.format(docs_content, question)
        
    else:
        strategy = "model_primary"
        prompt = """è¯·å›ç­”ä»¥ä¸‹é—®é¢˜ã€‚æˆ‘çš„çŸ¥è¯†åº“ä¸­æœ‰ä¸€äº›å¯èƒ½ç›¸å…³çš„ä¿¡æ¯ï¼Œè¯·ä¸»è¦åŸºäºä½ çš„çŸ¥è¯†å›ç­”ï¼Œä½†å¯ä»¥å‚è€ƒè¿™äº›ä¿¡æ¯ï¼š

å¯èƒ½ç›¸å…³çš„ä¿¡æ¯ï¼š
{}

é—®é¢˜ï¼š{}

è¯·ä¸»è¦åŸºäºä½ çš„çŸ¥è¯†è¿›è¡Œå›ç­”ï¼Œå¦‚æœçŸ¥è¯†åº“ä¸­çš„ä¿¡æ¯æœ‰å¸®åŠ©å¯ä»¥å‚è€ƒï¼š"""
        prompt = prompt.format(docs_content, question)
    
    return strategy, prompt

def init_vector_store(filepath=None, file_id=None, user_id=None, filename=None,ipfs_url=None):
    global vector_store

    if not filepath:
        if not vector_store and os.path.exists('chroma_db'):
            vector_store = Chroma(
                persist_directory='chroma_db',
                embedding_function=embeddings
            )
            count = vector_store._collection.count()
            print(f"æˆåŠŸåŠ è½½æœ¬åœ°çŸ¥è¯†åº“ï¼Œå…± {count} æ¡æ–‡æ¡£å—")
        return

    try:
        # å¤„ç†Windowsé£æ ¼çš„è·¯å¾„åˆ†éš”ç¬¦
        filepath = filepath.replace('\\', '/')
        print(f"æ­£åœ¨å¤„ç†: {filepath}, æ–‡ä»¶ID: {file_id}, ç”¨æˆ·ID: {user_id}, æ–‡ä»¶å: {filename}")

        if filepath.lower().endswith('.pdf'):
            loader = PyPDFLoader(filepath)
            documents = loader.load()
            print(f"PDF åŠ è½½æˆåŠŸï¼Œå…± {len(documents)} é¡µ")
        else:
            with open(filepath, "rb") as f:
                raw = f.read()
                detected = chardet.detect(raw)
                encoding = detected['encoding'] or 'utf-8'
            encoding = 'utf-16' if 'utf-16' in encoding.lower() else encoding
            encoding = 'gbk' if 'gb' in encoding.lower() else encoding
            try:
                loader = TextLoader(filepath, encoding=encoding)
                documents = loader.load()
                print(f"æˆåŠŸåŠ è½½æ–‡æœ¬ï¼ˆ{encoding}ï¼‰: {len(documents)} æ®µ")
            except:
                loader = TextLoader(filepath, encoding="utf-8", errors="ignore")
                documents = loader.load()

        cleaned_docs = []
        for doc in documents:
            text = doc.page_content.replace('\ufeff', '').replace('\u200b', '').replace('\u3000', ' ').replace('\xa0', ' ').strip()
            if not text:
                text = f"ï¼ˆç©ºæ–‡æ¡£ï¼Œæ¥æºï¼š{os.path.basename(filepath)}ï¼‰"
            doc.page_content = text
            
            # ğŸ¯ ä¿®å¤ï¼šç¡®ä¿æ–‡ä»¶IDè¢«æ­£ç¡®å­˜å‚¨
            # å¦‚æœfile_idä¸ºNoneï¼Œä»æ–‡ä»¶è·¯å¾„ä¸­æå–
            if file_id is None:
                file_id_from_path = os.path.basename(filepath).split('.')[0]
                doc.metadata['file_id'] = file_id_from_path
                print(f"ğŸ”„ ä»æ–‡ä»¶è·¯å¾„æå–file_id: {filepath} -> {file_id_from_path}")
            else:
                doc.metadata['file_id'] = file_id
            
            if user_id:
                doc.metadata['user_id'] = user_id
            if filename:
                doc.metadata['filename'] = filename

            doc.metadata['ipfs_url']=ipfs_url
            
            # ç¡®ä¿sourceä¹Ÿè¢«æ­£ç¡®è®¾ç½®
            doc.metadata['source'] = filepath
                
            cleaned_docs.append(doc)

        text_splitter = TokenTextSplitter(chunk_size=500, chunk_overlap=100)
        chunks = text_splitter.split_documents(cleaned_docs)
        if len(chunks) == 0:
            # åˆ›å»ºå ä½æ–‡æ¡£æ—¶ä¹Ÿè¦è®¾ç½®file_id
            placeholder_metadata = {"source": filepath}
            if file_id:
                placeholder_metadata['file_id'] = file_id
            chunks = [Document(page_content="ç©ºæ–‡æ¡£å ä½", metadata=placeholder_metadata)]

        print(f"æ–‡æ¡£å·²åˆ‡åˆ†ä¸º {len(chunks)} å—")
        
        # æ‰“å°ç¬¬ä¸€ä¸ªå—çš„metadataä½œä¸ºç¤ºä¾‹
        if chunks:
            print(f"ç¤ºä¾‹æ–‡æ¡£å—metadata: {chunks[0].metadata}")

        all_texts = [c.page_content for c in chunks]
        all_metadatas = [c.metadata for c in chunks]
        all_embeddings = []
        for i, text in enumerate(all_texts):
            embed_success = False
            for attempt in range(5):
                try:
                    embed = embeddings.embed_query(text)
                    all_embeddings.append(embed)
                    print(f"æ‰‹åŠ¨åµŒå…¥å— {i+1} æˆåŠŸ")
                    embed_success = True
                    break
                except Exception as e:
                    if "502" in str(e):
                        print(f"åµŒå…¥ 502ï¼Œé‡è¯•å— {i+1} ç¬¬ {attempt+1} æ¬¡...")
                        time.sleep(5)
                    else:
                        raise
            if not embed_success:
                raise Exception(f"åµŒå…¥å— {i+1} å¤±è´¥ï¼Œ5 æ¬¡é‡è¯•")

        if vector_store:
            vector_store.add_texts(
                texts=all_texts,
                embeddings=all_embeddings,
                metadatas=all_metadatas
            )
            print(f"æ–‡æ¡£å·²è¿½åŠ åˆ°çŸ¥è¯†åº“: {os.path.basename(filepath)}")
        else:
            class PrecomputedEmbeddings:
                def __init__(self, pre_embeds):
                    self.pre_embeds = pre_embeds

                def embed_documents(self, texts):
                    return self.pre_embeds

                def embed_query(self, text):
                    return self.pre_embeds[0]

            temp_embeddings = PrecomputedEmbeddings(all_embeddings)

            vector_store = Chroma.from_documents(
                documents=chunks,
                embedding=temp_embeddings,
                persist_directory='chroma_db'
            )
            print(f"æ‰‹åŠ¨æ–°å»ºçŸ¥è¯†åº“æˆåŠŸï¼æ–‡æ¡£æ•°: {len(chunks)}")

        print(f"æ–‡ä»¶å¤„ç†å®Œæˆ: {os.path.basename(filepath)}\n")

    except Exception as e:
        print(f"ä¸¥é‡é”™è¯¯ï¼æ–‡ä»¶å¤„ç†å½»åº•å¤±è´¥: {filepath}\né”™è¯¯ä¿¡æ¯: {str(e)}")
        raise

def enhanced_record_transaction(tx_type, from_user, to_user, amount, file_owner=None, file_id=None, question=None, details=None):
    """å¢å¼ºçš„äº¤æ˜“è®°å½•åŠŸèƒ½"""
    transactions = load_transactions()
    
    transaction = {
        'id': str(uuid.uuid4()),
        'type': tx_type,
        'from_user': from_user,
        'to_user': to_user,
        'amount': amount,
        'file_owner': file_owner,
        'file_id': file_id,
        'question': question,
        'details': details,  # æ–°å¢è¯¦ç»†ä¿¡æ¯å­—æ®µ
        'timestamp': datetime.now().isoformat()
    }
    
    transactions.append(transaction)
    save_transactions(transactions)
    
    # æ›´æ–°ç”¨æˆ·ä½™é¢
    conn = get_db_connection()
    
    if from_user and tx_type == 'spend':
        conn.execute('''
        UPDATE users SET 
            coin_balance = coin_balance - ?,
            total_spent = total_spent + ?
        WHERE user_id = ?
        ''', (amount, amount, from_user))

    if to_user and tx_type == 'reward':
        conn.execute('''
        UPDATE users SET 
            coin_balance = coin_balance + ?,
            total_earned = total_earned + ?
        WHERE user_id = ?
        ''', (amount, amount, to_user))

    conn.commit()
    conn.close()
    
    # è®°å½•è¯¦ç»†æ—¥å¿—
    log_transaction(transaction)

def log_transaction(transaction):
    """è®°å½•äº¤æ˜“æ—¥å¿—åˆ°æ–‡ä»¶"""
    log_entry = {
        'timestamp': datetime.now().isoformat(),
        'transaction': transaction
    }
    
    log_file = 'transaction_logs.json'
    logs = []
    
    if os.path.exists(log_file):
        try:
            with open(log_file, 'r', encoding='utf-8') as f:
                logs = json.load(f)
        except:
            logs = []
    
    logs.append(log_entry)
    
    with open(log_file, 'w', encoding='utf-8') as f:
        json.dump(logs, f, ensure_ascii=False, indent=2)
# ==================== Flask è·¯ç”± ====================

# @app.route('/')
# def index():
#     if 'user_id' in session:
#         return redirect('/dashboard')
#     return render_template('index.html')

# @app.route('/login', methods=['GET', 'POST'])
# def login():
#     if request.method == 'POST':
#         # æ”¯æŒè¡¨å•æ•°æ®å’ŒJSONæ•°æ®
#         if request.is_json:
#             data = request.get_json()
#             user_id = data.get('username', '').strip()
#             password = data.get('password', '').strip()
#         else:
#             user_id = request.form.get('user_id', '').strip()
#             password = request.form.get('password', '').strip()
        
#         success, message = authenticate_user(user_id, password)
#         if success:
#             session['user_id'] = user_id
#             return jsonify({'success': True, 'message': message})
#         else:
#             return jsonify({'success': False, 'message': message})
    
#     return render_template('login.html')

# @app.route('/register', methods=['GET', 'POST'])
# def register():
#     if request.method == 'POST':
#         user_id = request.form.get('user_id', '').strip()
#         password = request.form.get('password', '').strip()
        
#         success, message = register_user(user_id, password)
#         if success:
#             session['user_id'] = user_id
#             return jsonify({'success': True, 'message': message})
#         else:
#             return jsonify({'success': False, 'message': message})
    
#     return render_template('register.html')

# @app.route('/logout')
# def logout():
#     session.pop('user_id', None)
#     return redirect('/')

# @app.route('/dashboard')
# def dashboard():
#     # if 'user_id' not in session:
#     #     return redirect('/login')
#     users = load_users()

#     wallet_address = request.form.get('wallet_address', '').strip()
#     print("wallet_address:", wallet_address)

#     # print("wallet_address:", wallet_address)

#     if wallet_address not in users:
#         return jsonify({'success': False, 'message': 'é’±åŒ…æœªæ³¨å†Œï¼Œè¯·å…ˆè¿æ¥é’±åŒ…'})
    
#     user_id = wallet_address
    
#     user_stats = get_user_status(user_id )
#     shared_files = search_files(user_id=wallet_address)
    
#     vector_count = vector_store._collection.count() if vector_store else 0
    
#     return render_template('dashboard.html', 
#                          user_id=wallet_address,
#                          stats=user_stats,
#                          files=shared_files,
#                          vector_count=vector_count)



@app.route('/share', methods=['POST'])
def share_file():

    users = load_users()

    wallet_address = request.form.get('wallet_address', '').strip()
    print("wallet_address:", wallet_address)

    # print("wallet_address:", wallet_address)

    if wallet_address not in users:
        return jsonify({'success': False, 'message': 'é’±åŒ…æœªæ³¨å†Œï¼Œè¯·å…ˆè¿æ¥é’±åŒ…'})
    
    user_id = wallet_address

    # if 'user_id' not in session:
    #     return jsonify({'success': False, 'message': 'è¯·å…ˆè¿æ¥é’±åŒ…'})
    # ä¸ºäº†æµ‹è¯•ï¼Œå…è®¸æœªç™»å½•ç”¨æˆ·ä½¿ç”¨é»˜è®¤æµ‹è¯•è´¦å·
    # if 'user_id' not in session:
    #     # ä½¿ç”¨é»˜è®¤æµ‹è¯•è´¦å·
    #     user_id = 'test0'
    # else:
    #     user_id = session['user_id']
    
    filename = request.form.get('filename', '').strip()
    content = request.form.get('content', '').strip()
    authorize_rag = request.form.get('authorize_rag', 'false') == 'true'
    
    if not filename or not content:
        return jsonify({'success': False, 'message': 'æ–‡ä»¶åå’Œå†…å®¹ä¸èƒ½ä¸ºç©º'})
    
    file_id = save_shared_file(user_id, filename, content, authorize_rag)
    
    return jsonify({
        'success': True, 
        'message': 'æ–‡ä»¶åˆ†äº«æˆåŠŸ',
        'file_id': file_id
    })



@app.route('/file_content/<file_id>')
def get_file_content(file_id):
    if 'user_id' not in session:
        return jsonify({'success': False, 'message': 'è¯·å…ˆç™»å½•'})
    
    files = load_files()
    if file_id not in files:
        return jsonify({'success': False, 'message': 'æ–‡ä»¶ä¸å­˜åœ¨'})
    
    file_info = files[file_id]
    
    return jsonify({
        'success': True,
        'filename': file_info['filename'],
        'content': file_info['content'],
        'upload_time': file_info['upload_time'],
        'user_id': file_info['user_id'],
        'authorize_rag': file_info.get('authorize_rag', False),
        'reference_count': file_info.get('reference_count', 0),
        'total_reward': file_info.get('total_reward', 0)
    })

@app.route('/ask')
def ask_stream():

    users = load_users()
    wallet_address = request.args.get('wallet_address', '').strip()
    print("wallet_address:", wallet_address)

    if wallet_address not in users:
        return jsonify({'success': False, 'message': 'é’±åŒ…æœªæ³¨å†Œï¼Œè¯·å…ˆè¿æ¥é’±åŒ…'})
    
    user_id = wallet_address

    question = request.args.get('q', '').strip()
    
    print(f"ç”¨æˆ· {user_id} æé—®: {question}")
    
    if not question:
        return Response("data: é—®é¢˜ä¸èƒ½ä¸ºç©º\n\n", mimetype='text/event-stream')
    
    # æ£€æŸ¥ç”¨æˆ·ä½™é¢
    conn = get_db_connection()
    user = conn.execute('SELECT * FROM users WHERE user_id = ?', (user_id,)).fetchone()
    conn.close()
    
    if not user or user['coin_balance'] < 0.000001:
        return Response("data: Coinä½™é¢ä¸è¶³ï¼Œè¯·å……å€¼\n\n", mimetype='text/event-stream')
    
    def generate_response():
        should_use_rag = False
        rag_reason = ""
        confidence = 0.0
        relevant_docs = []
        
        try:
            conversation_cost = 0.000001
            record_transaction('spend', user_id, 'system', conversation_cost, None, None, question)
            
            # ä»æ•°æ®åº“è·å–æœ€æ–°ä½™é¢
            conn = get_db_connection()
            user = conn.execute('SELECT * FROM users WHERE user_id = ?', (user_id,)).fetchone()
            conn.close()
            
            if user:
                current_balance = user['coin_balance']
                print(f"ğŸ’° æœ¬æ¬¡å¯¹è¯æ¶ˆè€— {conversation_cost:.6f} coinï¼Œå½“å‰ä½™é¢: {current_balance:.6f} coin")
            
            if not vector_store or vector_store._collection.count() == 0:
                print("çŸ¥è¯†åº“ä¸ºç©ºï¼Œç›´æ¥åŸºäºæ¨¡å‹çŸ¥è¯†å›ç­”...")
                try:
                    # å…ˆå‘é€ä¸€ä¸ªæµ‹è¯•æ¶ˆæ¯
                    yield "data: æ­£åœ¨å¤„ç†æ‚¨çš„é—®é¢˜...\n\n"
                    
                    response = llm.invoke(question)
                    response_text = response.content if hasattr(response, 'content') else str(response)
                    print(f"LLMå“åº”å†…å®¹: {response_text[:50]}...")
                    
                    # å‘é€å®Œæ•´å›ç­”
                    yield f"data: {response_text}\n\n"
                    yield "data: [END]\n\n"
                except Exception as e:
                    import traceback
                    error_detail = traceback.format_exc()
                    print(f"LLMæœåŠ¡è¯¦ç»†é”™è¯¯:\n{error_detail}")
                    yield f"data: LLM æœåŠ¡é”™è¯¯: {str(e)}\n\n"
                    yield "data: [END]\n\n"
                return

            print("çŸ¥è¯†åº“å·²åŠ è½½ï¼Œå¼€å§‹æ£€ç´¢ç›¸å…³æ–‡æ¡£...")
            
            retriever = vector_store.as_retriever(search_kwargs={"k": 10})
            all_docs = retriever.invoke(question)
            
            print(f"ä»çŸ¥è¯†åº“æ£€ç´¢åˆ° {len(all_docs)} ä¸ªæ–‡æ¡£å—")
            
            if not all_docs:
                print("æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£ï¼Œå°†åŸºäºæ¨¡å‹çŸ¥è¯†å›ç­”")
                try:
                    response = llm.invoke(question)
                    response_text = response.content if hasattr(response, 'content') else str(response)
                    yield f"data: {response_text}\n\n"
                    yield "data: [END]\n\n"
                except Exception as e:
                    import traceback
                    error_detail = traceback.format_exc()
                    print(f"LLMæœåŠ¡è¯¦ç»†é”™è¯¯:\n{error_detail}")
                    yield f"data: LLM æœåŠ¡é”™è¯¯: {str(e)}\n\n"
                    yield "data: [END]\n\n"
                return
            
            try:
                print("å¼€å§‹æ™ºèƒ½è¿‡æ»¤ç›¸å…³æ–‡æ¡£...")
                relevant_docs = adaptive_filter_relevant_docs(question, all_docs, embeddings, llm)
                print(f"è¿‡æ»¤åä¿ç•™ {len(relevant_docs)} ä¸ªç›¸å…³æ–‡æ¡£")
            except Exception as e:
                print(f"æ™ºèƒ½è¿‡æ»¤å‡ºé”™: {str(e)}ï¼Œä½¿ç”¨æ‰€æœ‰æ£€ç´¢åˆ°çš„æ–‡æ¡£")
                relevant_docs = all_docs
            
            try:
                should_use_rag, rag_reason, confidence = intelligent_rag_decision(question, relevant_docs)
                print(f"{rag_reason} (ç½®ä¿¡åº¦: {confidence:.2f})")
            except Exception as e:
                print(f"æ™ºèƒ½å†³ç­–å‡ºé”™: {str(e)}ï¼Œé»˜è®¤ä½¿ç”¨RAG")
                should_use_rag, rag_reason, confidence = True, "é»˜è®¤ä½¿ç”¨RAG", 0.5
            
            # å¥–åŠ±åˆ†é…ä¿¡æ¯åªåœ¨åç«¯æ˜¾ç¤º
            if relevant_docs and should_use_rag:
                try:
                    print(f"å¼€å§‹å¥–åŠ±åˆ†é…: ç”¨æˆ· {user_id}, é—®é¢˜ '{question}', ç›¸å…³æ–‡æ¡£ {len(relevant_docs)} ä¸ª")
                    reward_distribution = distribute_rewards(user_id, question, relevant_docs, conversation_cost)
                    
                    if reward_distribution:
                        print("å¥–åŠ±åˆ†é…è¯¦æƒ…ï¼š")
                        total_distributed = 0
                        
                        for file_id, reward_info in reward_distribution.items():
                            files = load_files()
                            file_info = files.get(file_id, {})
                            filename = file_info.get('filename', 'æœªçŸ¥æ–‡ä»¶')
                            file_owner = file_info.get('user_id', 'æœªçŸ¥ç”¨æˆ·')
                            
                            reward_amount = reward_info['reward']
                            weight = reward_info['weight']
                            similarity = reward_info['similarity']
                            
                            total_distributed += reward_amount
                            
                            print(f"ğŸ“„ {filename} (ç”¨æˆ·: {file_owner})")
                            print(f"    ç›¸ä¼¼åº¦: {similarity:.3f} | æƒé‡: {weight:.3f} | å¥–åŠ±: {reward_amount:.8f} coin")
                        
                        print(f"ğŸ’° æ€»åˆ†é…é‡‘é¢: {total_distributed:.8f} coin")
                    else:
                        print("âš ï¸ æ²¡æœ‰è¿›è¡Œå¥–åŠ±åˆ†é…")
                        
                except Exception as e:
                    print(f"âŒ å¥–åŠ±åˆ†é…å‡ºé”™: {e}")
            
            # ğŸ¯ ä¿®å¤ï¼šä¼˜åŒ–AIå›ç­”ç”Ÿæˆéƒ¨åˆ†
            if should_use_rag and relevant_docs:
                try:
                    strategy, hybrid_prompt = hybrid_answering_strategy(question, relevant_docs, confidence)
                    print(f"ä½¿ç”¨å›ç­”ç­–ç•¥: {strategy}")

                    unique_sources = {}
                    for doc in relevant_docs:
                        src = doc.metadata.get("source", "æœªçŸ¥æ–‡ä»¶")
                        filename = os.path.basename(src)
                        # ğŸ¯ ä¿®æ”¹ï¼šå»æ‰æ–‡ä»¶æ‰©å±•åï¼Œåªæ˜¾ç¤ºæ–‡ä»¶å
                        filename_without_ext = os.path.splitext(filename)[0]
                        page = doc.metadata.get("page")
                        ipfs_url = doc.metadata.get("ipfs_url")
                        similarity = doc.metadata.get('semantic_similarity', 0)
                        
                        if filename not in unique_sources:
                            display_name = f"ã€Š{filename_without_ext}ã€‹"
                            display_name += f"ipfs_url:{ipfs_url}"
                            if page is not None:
                                display_name += f" (ç¬¬ {page + 1} é¡µ)"
                            display_name += f" [ç›¸å…³åº¦:{similarity:.2f}]"
                            
                            unique_sources[filename] = {
                                'display': display_name,
                                'similarity': similarity
                            }
                    
                    # å‘é€ç›¸å…³æ–‡æ¡£ä¿¡æ¯åˆ°å‰ç«¯
                    if unique_sources:
                        yield "data: ğŸ“š æœ¬æ¬¡å›ç­”å‚è€ƒäº†ä»¥ä¸‹æ–‡æ¡£ï¼š\n\n"
                        sorted_sources = sorted(unique_sources.values(), key=lambda x: x['similarity'], reverse=True)
                        for i, info in enumerate(sorted_sources):
                            yield f"data: {i+1}. {info['display']}\n"
                        yield "data: \n\n"
                    
                    print("æ­£åœ¨ç”Ÿæˆå›ç­”...")
                    
                    # ğŸ¯ ä¿®å¤ï¼šæ·»åŠ è¶…æ—¶ä¿æŠ¤å’Œé”™è¯¯å¤„ç†
                    try:
                        # è®¾ç½®ç”Ÿæˆå›ç­”çš„è¶…æ—¶æ—¶é—´
                        import threading
                        from queue import Queue, Empty
                        
                        response_queue = Queue()
                        error_queue = Queue()
                        
                        def generate_ai_response():
                            try:
                                response = llm.invoke(hybrid_prompt)
                                response_text = response.content if hasattr(response, 'content') else str(response)
                                response_queue.put(response_text)
                            except Exception as e:
                                error_queue.put(str(e))
                        
                        # åœ¨å•ç‹¬çš„çº¿ç¨‹ä¸­ç”Ÿæˆå›ç­”
                        thread = threading.Thread(target=generate_ai_response)
                        thread.daemon = True
                        thread.start()
                        
                        # ç­‰å¾…å›ç­”ç”Ÿæˆï¼Œæœ€å¤šç­‰å¾…60ç§’
                        thread.join(timeout=60)
                        
                        if thread.is_alive():
                            # å¦‚æœè¶…æ—¶ï¼Œå‘é€è¶…æ—¶ä¿¡æ¯
                            yield "data: â° ç”Ÿæˆå›ç­”è¶…æ—¶ï¼Œè¯·é‡è¯•\n\n"
                        elif not error_queue.empty():
                            # å¦‚æœæœ‰é”™è¯¯ï¼Œå‘é€é”™è¯¯ä¿¡æ¯
                            error_msg = error_queue.get()
                            yield f"data: ç”Ÿæˆå›ç­”æ—¶å‡ºé”™: {error_msg}\n\n"
                        else:
                            # æˆåŠŸç”Ÿæˆå›ç­”
                            response_text = response_queue.get()
                            yield f"data: {response_text}\n\n"
                            
                    except Exception as e:
                        print(f"AIå›ç­”ç”Ÿæˆå¼‚å¸¸: {e}")
                        yield f"data: ç”Ÿæˆå›ç­”æ—¶å‡ºç°å¼‚å¸¸: {str(e)}\n\n"
                        # å°è¯•ç®€åŒ–å›ç­”
                        try:
                            simple_response = llm.invoke(f"è¯·ç®€å•å›ç­”ï¼š{question}")
                            simple_text = simple_response.content if hasattr(simple_response, 'content') else str(simple_response)
                            yield f"data: ç®€åŒ–å›ç­”: {simple_text}\n\n"
                        except:
                            yield "data: æ— æ³•ç”Ÿæˆå›ç­”ï¼Œè¯·é‡è¯•\n\n"
                    
                except Exception as e:
                    print(f"å›ç­”ç­–ç•¥å‡ºé”™: {e}")
                    yield f"data: å›ç­”ç­–ç•¥å‡ºé”™: {str(e)}\n\n"

# ==================== åœ¨ app.py çš„ ask_stream å‡½æ•°ä¸­æ‰¾åˆ°æ¨¡å‹è‡ªèº«çŸ¥è¯†å›ç­”éƒ¨åˆ† ====================

# æ›¿æ¢è¿™ä¸ª else åˆ†æ”¯ï¼ˆæ¨¡å‹è‡ªèº«çŸ¥è¯†å›ç­”éƒ¨åˆ†ï¼‰
            # ==================== æ›¿ä»£æ–¹æ¡ˆï¼šåˆå¹¶å›ç­”å’Œæç¤ºä¿¡æ¯ ====================

            else:
                print("å°†åŸºäºæ¨¡å‹è‡ªèº«çŸ¥è¯†è¿›è¡Œå›ç­”...")
                try:
                    enhanced_prompt = f"è¯·å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š{question}"
                    
                    response = llm.invoke(enhanced_prompt)
                    response_text = response.content if hasattr(response, 'content') else str(response)
                    
                    # ğŸ¯ ä¿®å¤ï¼šç›´æ¥åœ¨å›ç­”å†…å®¹ä¸­æ·»åŠ æç¤ºä¿¡æ¯
                    full_response = response_text + "\n\n---\n\nğŸ’¡ **æœ¬æ¬¡å›ç­”åŸºäºæ¨¡å‹çš„è®­ç»ƒçŸ¥è¯†**"
                    
                    # æ¨¡æ‹Ÿæµå¼è¾“å‡º
                    import time
                    words = full_response.split(' ')
                    current_chunk = ""
                    
                    for i, word in enumerate(words):
                        current_chunk += word + " "
                        # æ¯4ä¸ªå•è¯æˆ–åˆ°è¾¾æœ«å°¾æ—¶å‘é€ä¸€æ¬¡
                        if i % 4 == 0 or i == len(words) - 1:
                            yield f"data: {current_chunk}\n\n"
                            current_chunk = ""
                            time.sleep(0.03)  # è½»å¾®å»¶è¿Ÿä»¥æ¨¡æ‹Ÿæµå¼æ•ˆæœ
                    
                    yield "data: [END]\n\n"
                    
                except Exception as e:
                    yield f"data: ç”Ÿæˆå›ç­”æ—¶å‡ºé”™: {str(e)}\n\n"
                    yield "data: [END]\n\n"
            yield "data: [END]\n\n"

        except Exception as e:
            import traceback
            error_details = traceback.format_exc()
            print(f"AIå¯¹è¯é”™è¯¯è¯¦æƒ…: {error_details}")
            yield f"data: ç³»ç»Ÿé”™è¯¯: {str(e)}\n\n"
            yield "data: [END]\n\n"

    return Response(generate_response(), mimetype='text/event-stream')


@app.route('/community')
def community():
    if 'user_id' not in session:
        return redirect('/login')
    
    files = search_files()
    return render_template('community.html', files=files, session=session)

@app.route('/file_detail/<file_id>')
def file_detail(file_id):
    if 'user_id' not in session:
        return redirect('/login')
    
    files = load_files()
    if file_id not in files:
        return "æ–‡ä»¶ä¸å­˜åœ¨", 404
    
    file_info = files[file_id]
    
    return render_template('file_detail.html', 
                         file_info=file_info,
                         user_id=session['user_id'])

@app.route('/vector_status')
def vector_status():
    if 'user_id' not in session:
        return jsonify({'success': False, 'message': 'è¯·å…ˆç™»å½•'})
    
    if not vector_store:
        return jsonify({
            'success': True,
            'vector_count': 0,
            'status': 'æœªåˆå§‹åŒ–'
        })
    
    count = vector_store._collection.count()
    return jsonify({
        'success': True,
        'vector_count': count,
        'status': f'å·²åŠ è½½ {count} ä¸ªæ–‡æ¡£å—'
    })

def add_content_to_vector_store(content, file_id, user_id, filename,ipfs_url):
    global vector_store
    
    try:
        from langchain_core.documents import Document
        
        # åˆ›å»ºDocumentå¯¹è±¡
        doc = Document(
            page_content=content,
            metadata={
                'file_id': file_id,
                'user_id': user_id,
                'filename': filename,
                'source': filename,
                'ipfs_url':ipfs_url
            }
        )
        
        # åˆ†å‰²æ–‡æ¡£
        text_splitter = TokenTextSplitter(chunk_size=500, chunk_overlap=100)
        docs = text_splitter.split_documents([doc])
        
        # åˆå§‹åŒ–æˆ–æ·»åŠ åˆ°å‘é‡åº“
        if vector_store is None:
            vector_store = Chroma.from_documents(
                documents=docs,
                embedding=embeddings,
                persist_directory='chroma_db'
            )
        else:
            vector_store.add_documents(docs)
        
        print(f"æˆåŠŸæ·»åŠ å†…å®¹åˆ°å‘é‡åº“: {filename} (å…± {len(docs)} å—)")
    except Exception as e:
        print(f"æ·»åŠ å†…å®¹åˆ°å‘é‡åº“å¤±è´¥: {e}")
        raise

@app.route('/reload_vector_store')
def reload_vector_store():
    # ä¸ºäº†æµ‹è¯•ï¼Œå…è®¸æœªç™»å½•ç”¨æˆ·ä½¿ç”¨é»˜è®¤æµ‹è¯•è´¦å·
    if 'user_id' not in session:
        # ä½¿ç”¨é»˜è®¤æµ‹è¯•è´¦å·
        user_id = 'test0'
    else:
        user_id = session['user_id']
    
    try:
        global vector_store
        
        files = load_files()
        authorized_files_count = 0
        
        # æ¸…ç†æ—§çš„å‘é‡åº“
        import shutil
        if os.path.exists('chroma_db'):
            shutil.rmtree('chroma_db')
        vector_store = None
        
        # é‡æ–°åŠ è½½æ‰€æœ‰æˆæƒçš„æ–‡ä»¶
        for file_id, file_info in files.items():
            if file_info.get('authorize_rag', False):
                # ä¼˜å…ˆä½¿ç”¨contentå­—æ®µç›´æ¥åŠ è½½
                content = file_info.get('content')
                user_id = file_info.get('user_id')
                filename = file_info.get('filename')
                ipfs_url= file_info.get('ipfs_url')
                
                if content and file_id:
                    try:
                        add_content_to_vector_store(content, file_id, user_id, filename,ipfs_url)
                        authorized_files_count += 1
                        print(f"é€šè¿‡contentåŠ è½½æ–‡ä»¶åˆ°çŸ¥è¯†åº“: {filename} (ID: {file_id})")
                    except Exception as e:
                        print(f"contentåŠ è½½å¤±è´¥ {filename}: {e}")
                else:
                    # å›é€€åˆ°file_pathåŠ è½½
                    file_path = file_info.get('file_path')
                    if file_path:
                        # è½¬æ¢Windowsè·¯å¾„
                        file_path = file_path.replace('\\', '/')
                        # ç¡®ä¿æ˜¯ç»å¯¹è·¯å¾„
                        if not os.path.isabs(file_path):
                            file_path = os.path.join(os.getcwd(), file_path)
                        
                        if os.path.exists(file_path):
                            try:
                                add_file_to_vector_store(file_path, file_id, user_id, filename,ipfs_url)
                                authorized_files_count += 1
                                print(f"é€šè¿‡file_pathåŠ è½½æ–‡ä»¶åˆ°çŸ¥è¯†åº“: {filename} (ID: {file_id})")
                            except Exception as e:
                                print(f"file_pathåŠ è½½å¤±è´¥ {filename}: {e}")
        
        final_count = vector_store._collection.count() if vector_store else 0
        
        return jsonify({
            'success': True,
            'message': f'çŸ¥è¯†åº“é‡æ–°åŠ è½½å®Œæˆï¼Œå…± {authorized_files_count} ä¸ªæˆæƒæ–‡ä»¶ï¼Œ{final_count} ä¸ªæ–‡æ¡£å—',
            'vector_count': final_count,
            'loaded_files': authorized_files_count
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'é‡æ–°åŠ è½½çŸ¥è¯†åº“å¤±è´¥: {str(e)}'
        })

    
@app.route('/health')
def health_check():
    # è·å–ç”¨æˆ·æ•°é‡
    conn = get_db_connection()
    user_count = conn.execute('SELECT COUNT(*) FROM users').fetchone()[0]
    conn.close()
    
    status = {
        "ollama_status": "unknown",
        "embedding_model": "unknown", 
        "llm_model": "unknown",
        "vector_store": "empty" if not vector_store else f"loaded ({vector_store._collection.count()} docs)",
        "user_count": user_count,
        "file_count": len(load_files())
    }
    
    try:
        test_embed = embeddings.embed_query("test")
        status["embedding_model"] = "ok"
        
        test_response = llm.invoke("hello")
        status["llm_model"] = "ok"
        status["ollama_status"] = "running"
        
    except Exception as e:
        status["ollama_status"] = f"error: {str(e)}"
    
    return jsonify(status)

@app.route('/files')
@app.route('/api/files')
def list_files():
    # æ”¯æŒä¸¤ç§è®¤è¯æ–¹å¼ï¼šsessionå’Œwallet_addresså‚æ•°
    user_id = None
    
    # æ£€æŸ¥session
    if 'user_id' in session:
        user_id = session['user_id']
    
    # å¦‚æœsessionä¸­æ²¡æœ‰ç”¨æˆ·IDï¼Œæ£€æŸ¥wallet_addresså‚æ•°
    if not user_id:
        wallet_address = request.args.get('wallet_address', '').strip()
        if wallet_address:
            user_id = wallet_address
    
    if not user_id:
        return jsonify({'success': False, 'message': 'è¯·å…ˆç™»å½•'})
    
    keyword = request.args.get('keyword', '').strip()
    file_id = request.args.get('file_id', '').strip()
    
    # ğŸ¯ ä¼˜åŒ–æœç´¢é€»è¾‘
    files = search_files(file_id=file_id if file_id else None, keyword=keyword)
    
    print(f"ğŸ” æœç´¢è¯·æ±‚ - å…³é”®è¯: '{keyword}', æ–‡ä»¶ID: '{file_id}', ç»“æœæ•°é‡: {len(files)}")
    
    return jsonify({
        'success': True,
        'files': files,
        'count': len(files)
    })

def search_files(file_id=None, user_id=None, keyword=None):
    """ä¼˜åŒ–æ–‡ä»¶æœç´¢åŠŸèƒ½"""
    files = load_files()
    results = []
    
    print(f"ğŸ” æœç´¢æ–‡ä»¶ - file_id: {file_id}, user_id: {user_id}, keyword: {keyword}")
    
    for fid, file_info in files.items():
        match = True
        
        if file_id and fid != file_id:
            match = False
        if user_id and file_info['user_id'] != user_id:
            match = False
        if keyword:
            keyword_lower = keyword.lower()
            # ğŸ¯ ä¼˜åŒ–ï¼šåœ¨æ–‡ä»¶åå’Œå†…å®¹ä¸­æœç´¢ï¼Œæé«˜æœç´¢å‡†ç¡®æ€§
            filename_match = keyword_lower in file_info['filename'].lower()
            content_match = keyword_lower in file_info['content'].lower()
            file_id_match = keyword_lower in fid.lower()
            user_id_match = keyword_lower in file_info['user_id'].lower()
            
            if not (filename_match or content_match or file_id_match or user_id_match):
                match = False
                
        if match:
            results.append({
                'file_id': fid,
                **file_info
            })
    
    # æŒ‰ä¸Šä¼ æ—¶é—´å€’åºæ’åˆ—
    sorted_results = sorted(results, key=lambda x: x['upload_time'], reverse=True)
    
    print(f"âœ… æœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(sorted_results)} ä¸ªæ–‡ä»¶")
    return sorted_results

@app.route('/community/files', methods=['GET'])
def get_community_files():
    """è·å–ç¤¾åŒºæ‰€æœ‰æ–‡ä»¶æˆ–æœç´¢æ–‡ä»¶"""
    try:
        print("ğŸ“¥ æ”¶åˆ°ç¤¾åŒºæ–‡ä»¶è¯·æ±‚")
        
        # è·å–æœç´¢å…³é”®è¯
        keyword = request.args.get('keyword', '').strip()
        print(f"ğŸ” æœç´¢å…³é”®è¯: '{keyword}'")
        
        # åŠ è½½æ–‡ä»¶æ•°æ®
        files = load_files()
        
        if not files:
            print("âš ï¸ files.jsonä¸ºç©ºæˆ–ä¸å­˜åœ¨")
            return jsonify({
                'success': True,
                'message': 'æš‚æ— æ–‡ä»¶æ•°æ®',
                'files': [],
                'total_count': 0
            })
        
        # å¤„ç†æ–‡ä»¶æ•°æ®
        file_list = []
        
        if keyword:
            # æ‰§è¡Œæœç´¢
            print(f"ğŸ” å¼€å§‹æœç´¢ï¼Œå…³é”®è¯: {keyword}")
            search_results = search_files_in_content(files, keyword)
            print(f"âœ… æ‰¾åˆ° {len(search_results)} ä¸ªåŒ¹é…æ–‡ä»¶")
            
            for file_id in search_results:
                file_data = files[file_id]
                file_list.append({
                    'file_id': file_id,
                    'filename': file_data.get('filename', ''),
                    'user_id': file_data.get('user_id', ''),
                    'content': file_data.get('content_preview', file_data.get('content', '')),
                    'content_full': file_data.get('content', ''),
                    'upload_time': file_data.get('upload_time', ''),
                    'reference_count': file_data.get('reference_count', 0),
                    'total_reward': file_data.get('total_reward', 0.0),
                    'authorize_rag': file_data.get('authorize_rag', False),
                    'ipfs_url': file_data.get('ipfs_url', '')
                })
        else:
            # è¿”å›æ‰€æœ‰æ–‡ä»¶
            print(f"ğŸ“‚ è¿”å›æ‰€æœ‰æ–‡ä»¶ï¼Œå…± {len(files)} ä¸ª")
            for file_id, file_data in files.items():
                file_list.append({
                    'file_id': file_id,
                    'filename': file_data.get('filename', ''),
                    'user_id': file_data.get('user_id', ''),
                    'content': file_data.get('content_preview', file_data.get('content', '')),
                    'content_full': file_data.get('content', ''),
                    'upload_time': file_data.get('upload_time', ''),
                    'reference_count': file_data.get('reference_count', 0),
                    'total_reward': file_data.get('total_reward', 0.0),
                    'authorize_rag': file_data.get('authorize_rag', False),
                    'ipfs_url': file_data.get('ipfs_url', '')
                })
        
        # æŒ‰ä¸Šä¼ æ—¶é—´å€’åºæ’åº
        file_list.sort(key=lambda x: x.get('upload_time', ''), reverse=True)
        
        print(f"âœ… è¿”å› {len(file_list)} ä¸ªæ–‡ä»¶")
        return jsonify({
            'success': True,
            'message': 'æ–‡ä»¶æ•°æ®è·å–æˆåŠŸ',
            'files': file_list,
            'total_count': len(file_list)
        })
        
    except Exception as e:
        print(f"âŒ è·å–ç¤¾åŒºæ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'message': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}',
            'files': [],
            'total_count': 0
        }), 500

@app.route('/community/file/<file_id>', methods=['GET'])
def get_file_detail(file_id):
    """è·å–å•ä¸ªæ–‡ä»¶çš„è¯¦ç»†ä¿¡æ¯"""
    try:
        print(f"ğŸ“¥ è·å–æ–‡ä»¶è¯¦æƒ…ï¼Œæ–‡ä»¶ID: {file_id}")
        
        # åŠ è½½æ–‡ä»¶æ•°æ®
        files = load_files()
        
        if not files:
            print("âš ï¸ files.jsonä¸ºç©ºæˆ–ä¸å­˜åœ¨")
            return jsonify({
                'success': False,
                'message': 'æ–‡ä»¶æ•°æ®åº“ä¸ºç©º'
            }), 404
        
        if file_id not in files:
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_id}")
            return jsonify({
                'success': False,
                'message': 'æ–‡ä»¶ä¸å­˜åœ¨'
            }), 404
        
        file_data = files[file_id]
        
        # è·å–ç”¨æˆ·ä¿¡æ¯ï¼ˆå¦‚æœéœ€è¦ï¼‰
        user_id = file_data.get('user_id', '')
        
        print(f"âœ… æ‰¾åˆ°æ–‡ä»¶: {file_data.get('filename')}")
        return jsonify({
            'success': True,
            'message': 'æ–‡ä»¶è¯¦æƒ…è·å–æˆåŠŸ',
            'file_info': {
                'file_id': file_id,
                'filename': file_data.get('filename', ''),
                'user_id': user_id,
                'content': file_data.get('content', ''),
                'content_preview': file_data.get('content_preview', ''),
                'upload_time': file_data.get('upload_time', ''),
                'reference_count': file_data.get('reference_count', 0),
                'total_reward': file_data.get('total_reward', 0.0),
                'authorize_rag': file_data.get('authorize_rag', False),
                'ipfs_url': file_data.get('ipfs_url', ''),
                'file_path': file_data.get('file_path', '')
            }
        })
        
    except Exception as e:
        print(f"âŒ è·å–æ–‡ä»¶è¯¦æƒ…æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'message': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}'
        }), 500

@app.route('/community/stats', methods=['GET'])
def get_community_stats():
    """è·å–ç¤¾åŒºç»Ÿè®¡ä¿¡æ¯"""
    try:
        print("ğŸ“Š è·å–ç¤¾åŒºç»Ÿè®¡ä¿¡æ¯")
        
        files = load_files()
        
        if not files:
            print("âš ï¸ files.jsonä¸ºç©ºæˆ–ä¸å­˜åœ¨")
            return jsonify({
                'success': True,
                'message': 'æš‚æ— ç»Ÿè®¡ä¿¡æ¯',
                'stats': {
                    'total_files': 0,
                    'total_references': 0,
                    'total_rewards': 0.0,
                    'active_authors': 0
                }
            })
        
        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        total_files = len(files)
        total_references = sum(f.get('reference_count', 0) for f in files.values())
        total_rewards = sum(f.get('total_reward', 0.0) for f in files.values())
        
        # ç»Ÿè®¡æ´»è·ƒä½œè€…
        authors = set()
        for file_data in files.values():
            authors.add(file_data.get('user_id', ''))
        active_authors = len(authors)
        
        print(f"ğŸ“Š ç¤¾åŒºç»Ÿè®¡: æ–‡ä»¶={total_files}, å¼•ç”¨={total_references}, æ”¶ç›Š={total_rewards}, ä½œè€…={active_authors}")
        
        return jsonify({
            'success': True,
            'message': 'ç»Ÿè®¡ä¿¡æ¯è·å–æˆåŠŸ',
            'stats': {
                'total_files': total_files,
                'total_references': total_references,
                'total_rewards': total_rewards,
                'active_authors': active_authors
            }
        })
        
    except Exception as e:
        print(f"âŒ è·å–ç¤¾åŒºç»Ÿè®¡æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return jsonify({
            'success': False,
            'message': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}'
        }), 500


# WebSocketäº‹ä»¶å¤„ç†
@socketio.on('connect', namespace='/ws')
def handle_connect():
    """å¤„ç†WebSocketè¿æ¥äº‹ä»¶"""
    print("å®¢æˆ·ç«¯å·²è¿æ¥åˆ°WebSocket")
    emit('system_message', {'type': 'info', 'content': 'åç«¯WebSocketè¿æ¥æˆåŠŸ'})


@app.route('/api/test_system_message', methods=['GET'])
def test_system_message():
    """æµ‹è¯•æ¥å£ï¼šå‘é€ç³»ç»Ÿæ¶ˆæ¯"""
    message_content = request.args.get('content', 'è¿™æ˜¯ä¸€æ¡æµ‹è¯•ç³»ç»Ÿæ¶ˆæ¯')
    message_type = request.args.get('type', 'info')
    
    # éªŒè¯æ¶ˆæ¯ç±»å‹
    valid_types = ['info', 'success', 'warning', 'error']
    if message_type not in valid_types:
        message_type = 'info'
    
    send_system_message(message_type, message_content)
    return jsonify({'success': True, 'message': 'ç³»ç»Ÿæ¶ˆæ¯å·²å‘é€'})


def send_system_message(message_type, content):
    """å‘é€ç³»ç»Ÿæ¶ˆæ¯ç»™æ‰€æœ‰è¿æ¥çš„å®¢æˆ·ç«¯"""
    socketio.emit('system_message', {
        'type': message_type,
        'content': content
    }, namespace='/ws')
    print(f"å‘é€ç³»ç»Ÿæ¶ˆæ¯: [{message_type}] {content}")


@app.route('/api/test_intent', methods=['GET'])
def test_intent():
    """æµ‹è¯•å‘é€è½¬è´¦æ„å›¾JSONæ¶ˆæ¯"""
    try:
        # æ¨¡æ‹Ÿçš„è½¬è´¦æ„å›¾JSONæ•°æ®
        intent_data = {
            'action': 'transfer',
            'fromChain': 'zetachain',
            'toChain': 'zetachain',
            'fromToken': 'ZETA',
            'toToken': 'ZETA',
            'amount': '0.01',
            'recipient': '0xeb2eb574be8001ef7ff3c60bd56caac4ed58fab2'
        }
        
        # å‘é€åŒ…å«è½¬è´¦æ„å›¾çš„ç³»ç»Ÿæ¶ˆæ¯
        socketio.emit('system_message', {
            'type': 'info',
            'content': f'æ”¶åˆ°è½¬è´¦è¯·æ±‚ï¼š{intent_data["amount"]} {intent_data["fromToken"]} åˆ° {intent_data["recipient"]}',
            **intent_data
        }, namespace='/ws')
        
        return jsonify({'status': 'success', 'message': 'è½¬è´¦æ„å›¾æ¶ˆæ¯å·²å‘é€'}), 200
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/api/test_qwen_api', methods=['GET'])
def test_qwen_api_route():
    """æµ‹è¯•Qwen APIè¿æ¥"""
    try:
        test_question = "æµ‹è¯•Qwen APIè¿æ¥"
        print(f"æµ‹è¯•Qwen API: {test_question}")
        
        # ç›´æ¥è°ƒç”¨Qwen API
        response = llm.invoke(test_question)
        response_text = response.content if hasattr(response, 'content') else str(response)
        
        print(f"Qwen APIæµ‹è¯•æˆåŠŸ: {response_text}")
        return jsonify({'status': 'success', 'message': response_text}), 200
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"Qwen APIæµ‹è¯•å¤±è´¥:\n{error_detail}")
        return jsonify({'status': 'error', 'message': str(e), 'detail': error_detail}), 500

@app.route('/api/test_simple_ask', methods=['GET'])
def test_simple_ask():
    """æµ‹è¯•ç®€å•çš„LLMè°ƒç”¨ï¼ˆéSSEï¼‰"""
    try:
        question = request.args.get('q', 'ä¸ºä»€ä¹ˆäººç±»éœ€è¦çˆ±ï¼Ÿ')
        print(f"æµ‹è¯•ç®€å•æé—®: {question}")
        
        # ç›´æ¥è°ƒç”¨Qwen API
        response = llm.invoke(question)
        response_text = response.content if hasattr(response, 'content') else str(response)
        
        print(f"ç®€å•æé—®æµ‹è¯•æˆåŠŸ: {response_text}")
        return jsonify({'status': 'success', 'question': question, 'answer': response_text}), 200
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"ç®€å•æé—®æµ‹è¯•å¤±è´¥:\n{error_detail}")
        return jsonify({'status': 'error', 'message': str(e), 'detail': error_detail}), 500


@app.route('/dashboard', methods=['GET'])
@app.route('/api/dashboard', methods=['GET'])
def get_dashboard_data():
    """è·å–ä»ªè¡¨ç›˜æ•°æ® - åŒæ—¶æ”¯æŒ /dashboard å’Œ /api/dashboard è·¯å¾„"""
    wallet_address = request.args.get('wallet_address', '').strip()
    
    print(f"ğŸ“Š Dashboard API è°ƒç”¨ï¼Œé’±åŒ…åœ°å€: {wallet_address}")
    
    if not wallet_address:
        print("âš ï¸ é’±åŒ…åœ°å€ä¸ºç©º")
        return jsonify({'success': False, 'message': 'é’±åŒ…åœ°å€ä¸èƒ½ä¸ºç©º'})
    
    # ä»JSONæ–‡ä»¶åŠ è½½æ•°æ®
    users = load_users()
    
    print(f"ğŸ” æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å­˜åœ¨ï¼Œé’±åŒ…åœ°å€: {wallet_address}")
    print(f"ğŸ“ ç”¨æˆ·åˆ—è¡¨ä¸­çš„ç”¨æˆ·: {list(users.keys())}")
    
    # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å­˜åœ¨
    if wallet_address not in users:
        # æ£€æŸ¥æ˜¯å¦ä½œä¸ºwallet_accountå­˜åœ¨
        user_found = False
        user_id = None
        for uid, user_data in users.items():
            if user_data.get('wallet_account') == wallet_address:
                user_found = True
                user_id = uid
                print(f"âœ… é€šè¿‡wallet_accountæ‰¾åˆ°ç”¨æˆ·: {uid}")
                break
        
        if not user_found:
            print(f"âŒ ç”¨æˆ·ä¸å­˜åœ¨äºusers.json: {wallet_address}")
            return jsonify({'success': False, 'message': 'é’±åŒ…æœªæ³¨å†Œï¼Œè¯·å…ˆè¿æ¥é’±åŒ…'})
    else:
        user_id = wallet_address
        print(f"âœ… ç”¨æˆ·IDç›´æ¥åŒ¹é…: {user_id}")
    
    user_data = users[user_id]
    
    # è®¡ç®—ç»Ÿè®¡æ•°æ®
    # 1. æ€»æ”¶ç›Š - ç›´æ¥ä»users.jsonè·å–
    total_earned = user_data.get('total_earned', 0.0)
    print(f"ğŸ’° æ€»æ”¶ç›Š: {total_earned}")
    
    # 2. Data NFTæ•°é‡ï¼ˆä¸Šä¼ çš„æ–‡ä»¶æ•°é‡ï¼‰
    data_nft_count = len(user_data.get('uploaded_files', []))
    print(f"ğŸ“ Data NFTæ•°é‡: {data_nft_count}")
    
    # 3. AIè°ƒç”¨æ¬¡æ•°ï¼ˆä»Šæ—¥å¼•ç”¨æ¬¡æ•°ï¼‰
    transactions = load_transactions()
    today = datetime.now().date()
    
    ai_calls_today = 0
    for tx in transactions:
        tx_time = datetime.fromisoformat(tx['timestamp']).date()
        if tx_time == today and tx.get('file_owner') == user_id and tx['type'] == 'reference':
            ai_calls_today += 1
    
    print(f"ğŸ¤– ä»Šæ—¥AIè°ƒç”¨æ¬¡æ•°: {ai_calls_today}")
    
    # 4. æœ¬æœˆå¢é•¿ï¼ˆæœ¬æœˆæ”¶ç›Šï¼‰
    current_month = datetime.now().strftime('%Y-%m')
    monthly_growth = 0.0
    
    for tx in transactions:
        if tx['type'] == 'reward' and tx['to_user'] == user_id:
            tx_time = datetime.fromisoformat(tx['timestamp'])
            if tx_time.strftime('%Y-%m') == current_month:
                monthly_growth += tx['amount']
    
    print(f"ğŸ“ˆ æœ¬æœˆå¢é•¿: {monthly_growth}")
    
    # è·å–æœ€è¿‘æ´»åŠ¨ï¼ˆäº¤æ˜“è®°å½•ï¼‰
    recent_activity = []
    user_transactions = []
    
    for tx in transactions:
        if tx['from_user'] == user_id or tx['to_user'] == user_id or tx.get('file_owner') == user_id:
            user_transactions.append(tx)
    
    # æŒ‰æ—¶é—´å€’åºæ’åˆ—ï¼Œå–æœ€è¿‘5æ¡
    user_transactions.sort(key=lambda x: x['timestamp'], reverse=True)
    
    for i, tx in enumerate(user_transactions[:5]):
        activity_type = ""
        content = ""
        
        if tx['type'] == 'reward' and tx['to_user'] == user_id:
            activity_type = "æ”¶ç›Š"
            content = f"AI æ¨¡å‹è°ƒç”¨æ”¶ç›Š +{tx['amount']:.6f} USDT"
        elif tx['type'] == 'spend' and tx['from_user'] == user_id:
            activity_type = "æ”¯å‡º"
            content = f"AI æé—®æ”¯å‡º -{tx['amount']:.6f} USDT"
        elif tx['type'] == 'reference' and tx.get('file_owner') == user_id:
            activity_type = "å¼•ç”¨"
            content = f"æ‚¨çš„å†…å®¹è¢« AI å¼•ç”¨"
        elif tx['type'] == 'reward' and tx.get('file_owner') == user_id:
            activity_type = "æ”¶ç›Š"
            content = f"æ•°æ®æˆæƒæ”¶ç›Š +{tx['amount']:.6f} USDT"
        
        if activity_type:
            # è®¡ç®—ç›¸å¯¹æ—¶é—´
            tx_time = datetime.fromisoformat(tx['timestamp'])
            now = datetime.now()
            time_diff = now - tx_time
            
            if time_diff.total_seconds() < 3600:
                time_str = f"{int(time_diff.total_seconds() / 60)}åˆ†é’Ÿå‰"
            elif time_diff.total_seconds() < 86400:
                time_str = f"{int(time_diff.total_seconds() / 3600)}å°æ—¶å‰"
            else:
                time_str = f"{int(time_diff.total_seconds() / 86400)}å¤©å‰"
            
            recent_activity.append({
                'id': i + 1,
                'type': activity_type,
                'content': content,
                'time': time_str,
                'timestamp': tx['timestamp']
            })
    
    # è·å–å†…å®¹æº¯æºï¼ˆç”¨æˆ·ä¸Šä¼ çš„æ–‡ä»¶ä¿¡æ¯ï¼‰
    files = load_files()
    content_tracing = []
    
    uploaded_file_ids = user_data.get('uploaded_files', [])
    print(f"ğŸ“„ ç”¨æˆ·ä¸Šä¼ çš„æ–‡ä»¶ID: {uploaded_file_ids}")
    
    for file_id in uploaded_file_ids[:5]:  # åªå–å‰5ä¸ªæ–‡ä»¶
        if file_id in files:
            file_info = files[file_id]
            content_tracing.append({
                'file_id': file_id,
                'filename': file_info['filename'],
                'reference_count': file_info.get('reference_count', 0),
                'total_reward': file_info.get('total_reward', 0.0),
                'content_preview': file_info.get('content_preview', ''),
                'ipfs_url': file_info.get('ipfs_url', ''),
                'authorize_rag': file_info.get('authorize_rag', False)
            })
        else:
            print(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {file_id}")
    
    print(f"âœ… æ•°æ®å‡†å¤‡å®Œæˆï¼Œè¿”å›ç»™å‰ç«¯")
    
    # æ ¼å¼åŒ–æ•°æ®
    return jsonify({
        'success': True,
        'message': 'æ•°æ®è·å–æˆåŠŸ',
        'data': {
            'stats': {
                'total_earned': {
                    'label': 'æ€»æ”¶ç›Š',
                    'value': f"{total_earned:.6f} USDT",
                    'raw_value': total_earned
                },
                'data_nft': {
                    'label': 'Data NFT',
                    'value': str(data_nft_count),
                    'raw_value': data_nft_count
                },
                'ai_calls': {
                    'label': 'AI è°ƒç”¨æ¬¡æ•°',
                    'value': str(ai_calls_today),
                    'raw_value': ai_calls_today
                },
                'monthly_growth': {
                    'label': 'æœ¬æœˆå¢é•¿',
                    'value': f"+{monthly_growth:.6f} USDT" if monthly_growth > 0 else f"{monthly_growth:.6f} USDT",
                    'raw_value': monthly_growth
                }
            },
            'recent_activity': recent_activity,
            'content_tracing': content_tracing,
            'user_info': {
                'user_id': user_id,
                'wallet_address': user_data.get('wallet_account', user_id),
                'coin_balance': user_data.get('coin_balance', 0.0),
                'total_earned': user_data.get('total_earned', 0.0),
                'total_spent': user_data.get('total_spent', 0.0)
            }
        }
    })



@app.route('/dashboard', methods=['GET'])
def dashboard_api():
    """Dashboard API - ç”¨äºä»£ç†è½¬å‘çš„è·¯ç”±"""
    # è¿™é‡Œç›´æ¥è°ƒç”¨ get_dashboard_data å‡½æ•°
    return get_dashboard_data()

@app.route('/api/user/stats', methods=['GET'])
def get_user_stats_api():
    """è·å–ç”¨æˆ·ç»Ÿè®¡ä¿¡æ¯ï¼ˆç®€åŒ–ç‰ˆï¼‰- åªä½¿ç”¨JSONæ–‡ä»¶"""
    wallet_address = request.args.get('wallet_address', '').strip()
    
    if not wallet_address:
        return jsonify({'success': False, 'message': 'é’±åŒ…åœ°å€ä¸èƒ½ä¸ºç©º'})
    
    # ä»JSONæ–‡ä»¶åŠ è½½æ•°æ®
    users = load_users()
    
    # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å­˜åœ¨
    if wallet_address not in users:
        # æ£€æŸ¥æ˜¯å¦ä½œä¸ºwallet_accountå­˜åœ¨
        user_found = False
        user_id = None
        for uid, user_data in users.items():
            if user_data.get('wallet_account') == wallet_address:
                user_found = True
                user_id = uid
                break
        
        if not user_found:
            return jsonify({'success': False, 'message': 'ç”¨æˆ·ä¸å­˜åœ¨'})
    else:
        user_id = wallet_address
    
    user_data = users[user_id]
    
    # è·å–ä»Šæ—¥æ”¶ç›Šå’Œå¼•ç”¨
    today = datetime.now().date()
    transactions = load_transactions()
    
    today_earned = 0.0
    today_references = 0
    
    for tx in transactions:
        tx_time = datetime.fromisoformat(tx['timestamp']).date()
        if tx_time == today:
            if tx['type'] == 'reward' and tx['to_user'] == user_id:
                today_earned += tx['amount']
            elif tx['type'] == 'reference' and tx.get('file_owner') == user_id:
                today_references += 1
    
    # è·å–ä¸Šä¼ æ–‡ä»¶æ•°é‡
    uploaded_files_count = len(user_data.get('uploaded_files', []))
    
    return jsonify({
        'success': True,
        'data': {
            'coin_balance': user_data.get('coin_balance', 0.0),
            'total_earned': user_data.get('total_earned', 0.0),
            'total_spent': user_data.get('total_spent', 0.0),
            'today_earned': today_earned,
            'today_references': today_references,
            'uploaded_files_count': uploaded_files_count,
            'wallet_address': user_data.get('wallet_account', user_id)
        }
    })


@app.route('/stake', methods=['POST'])
def handle_stake():
    """å¤„ç†è´¨æŠ¼ä¿¡æ¯çš„å†™å…¥"""
    try:
        # è§£æè¯·æ±‚ä½“
        data = request.get_json()
        
        # éªŒè¯å¿…è¦å­—æ®µ
        required_fields = ['file_id', 'wallet_address', 'amount', 'content_id']
        for field in required_fields:
            if field not in data or not data[field]:
                return jsonify({'success': False, 'message': f'{field}å­—æ®µä¸èƒ½ä¸ºç©º'})
        
        file_id = data['file_id']
        wallet_address = data['wallet_address']
        amount = float(data['amount'])
        content_id = data['content_id']
        
        # å†™å…¥æ•°æ®åº“
        conn = get_db_connection()
        conn.execute('''
        INSERT INTO stakes (file_id, wallet_address, amount, content_id)
        VALUES (?, ?, ?, ?)
        ''', (file_id, wallet_address, amount, content_id))
        conn.commit()
        conn.close()
        
        # æ›´æ–°æ•°æ®åº“ä¸­çš„filesè¡¨çš„total_stakedå­—æ®µ
        conn = get_db_connection()
        conn.execute('''
        UPDATE files 
        SET total_staked = total_staked + ? 
        WHERE id = ?
        ''', (amount, file_id))
        conn.commit()
        conn.close()
        
        # åŒæ—¶æ›´æ–°JSONæ–‡ä»¶ä»¥ä¿æŒå…¼å®¹æ€§
        files = load_files()
        if file_id in files:
            files[file_id]['total_staked'] = files[file_id].get('total_staked', 0) + amount
            save_files(files)
        
        return jsonify({
            'success': True,
            'message': 'è´¨æŠ¼ä¿¡æ¯å·²æˆåŠŸå†™å…¥æ•°æ®åº“'
        })
    
    except json.JSONDecodeError:
        return jsonify({'success': False, 'message': 'è¯·æ±‚ä½“ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼'})
    except ValueError:
        return jsonify({'success': False, 'message': 'amountå­—æ®µå¿…é¡»æ˜¯æœ‰æ•ˆçš„æ•°å­—'})
    except Exception as e:
        print(f"å¤„ç†è´¨æŠ¼è¯·æ±‚æ—¶å‡ºé”™: {str(e)}")
        return jsonify({'success': False, 'message': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}'})


@app.route('/stake', methods=['GET'])
def get_stakes():
    """è·å–è´¨æŠ¼è®°å½•"""
    try:
        # è·å–æŸ¥è¯¢å‚æ•°
        wallet_address = request.args.get('wallet_address', '').strip()
        file_id = request.args.get('file_id', '').strip()
        
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # æ„å»ºæŸ¥è¯¢è¯­å¥ï¼Œå…³è”filesè¡¨è·å–æ–‡ä»¶å
        query = """
            SELECT 
                t2.filename, 
                t1.amount, 
                t1.stake_time, 
                t1.id, 
                t1.file_id, 
                t1.wallet_address, 
                t1.content_id
            FROM stakes t1 
            LEFT JOIN files t2 ON t1.file_id = t2.id 
            WHERE 1=1
        """
        params = []
        
        if wallet_address:
            query += " AND t1.wallet_address = ?"
            params.append(wallet_address)               
        
        # æŒ‰æ—¶é—´å€’åºæ’åˆ—
        query += " ORDER BY t1.stake_time DESC"

        print(query, params)
        
        cursor.execute(query, params)
        stakes = cursor.fetchall()
        conn.close()
        
        for stake in stakes:
            print(stake)

        # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
        stake_list = []
        for stake in stakes:
            stake_list.append({
                'id': stake['id'],
                'file_id': stake['file_id'],
                'wallet_address': stake['wallet_address'],
                'amount': stake['amount'],
                'content_id': stake['content_id'],
                'stake_time': stake['stake_time'],
                'filename': stake['filename']  # æ–°å¢æ–‡ä»¶åå­—æ®µ
            })
        
        return jsonify({
            'success': True,
            'stakes': stake_list,
            'count': len(stake_list)
        })
    
    except Exception as e:
        print(f"è·å–è´¨æŠ¼è®°å½•æ—¶å‡ºé”™: {str(e)}")
        return jsonify({'success': False, 'message': f'æœåŠ¡å™¨é”™è¯¯: {str(e)}'})



if __name__ == '__main__':
    print("ğŸš€ å¯åŠ¨å¤šç”¨æˆ·AIçŸ¥è¯†åº“å¹³å°...")
    print("ğŸ“š åˆå§‹åŒ–å‘é‡åº“...")
    init_vector_store()
    
    if vector_store:
        try:
            count = vector_store._collection.count()
            print(f"âœ… å‘é‡åº“åŠ è½½æˆåŠŸï¼ŒåŒ…å« {count} ä¸ªæ–‡æ¡£")
        except Exception as e:
            print(f"âŒ å‘é‡åº“è®¿é—®é”™è¯¯: {e}")
    else:
        print("âš ï¸  å‘é‡åº“æœªåŠ è½½ï¼ŒçŸ¥è¯†åº“ä¸ºç©º")
    
    # å‘é€å¯åŠ¨æ¶ˆæ¯
    print("ğŸŒ æ­£åœ¨å¯åŠ¨æœåŠ¡å™¨...")
    
    # ä½¿ç”¨socketio.run()æ›¿ä»£app.run()ä»¥æ”¯æŒWebSocket
    socketio.run(app, host='127.0.0.1', port=5001, debug=True)
